{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95bb1d40-e44c-43a2-b15d-6f745d44f91b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "472ad4d6-c05c-4432-9b96-11d003b80986",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Workspace/Users/giridharanvel%40gmail.com/.bundle/marvelous-databricks-course-Giri-Vel/dev/files_2/Giri-Vel-marvelous-databricks-course-Giri-Vel\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Checking if build backend supports build_editable: started\n  Checking if build backend supports build_editable: finished with status 'done'\n  Getting requirements to build editable: started\n  Getting requirements to build editable: finished with status 'done'\n  Preparing editable metadata (pyproject.toml): started\n  Preparing editable metadata (pyproject.toml): finished with status 'done'\nCollecting mlflow==2.17.0 (from hotel-reservations==0.0.1)\n  Obtaining dependency information for mlflow==2.17.0 from https://files.pythonhosted.org/packages/bd/af/fdf92ad9f654f2210f225a56b4d45698f6f171d69c1195461b9fa18c5543/mlflow-2.17.0-py3-none-any.whl.metadata\n  Downloading mlflow-2.17.0-py3-none-any.whl.metadata (29 kB)\nCollecting cffi==1.17.1 (from hotel-reservations==0.0.1)\n  Obtaining dependency information for cffi==1.17.1 from https://files.pythonhosted.org/packages/ff/6b/d45873c5e0242196f042d555526f92aa9e0c32355a1be1ff8c27f077fd37/cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting cloudpickle==3.1.0 (from hotel-reservations==0.0.1)\n  Obtaining dependency information for cloudpickle==3.1.0 from https://files.pythonhosted.org/packages/48/41/e1d85ca3cab0b674e277c8c4f678cf66a91cd2cecf93df94353a606fe0db/cloudpickle-3.1.0-py3-none-any.whl.metadata\n  Downloading cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\nCollecting matplotlib==3.9.2 (from hotel-reservations==0.0.1)\n  Obtaining dependency information for matplotlib==3.9.2 from https://files.pythonhosted.org/packages/01/75/6c7ce560e95714a10fcbb3367d1304975a1a3e620f72af28921b796403f3/matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting numpy==1.26.4 (from hotel-reservations==0.0.1)\n  Obtaining dependency information for numpy==1.26.4 from https://files.pythonhosted.org/packages/3a/d0/edc009c27b406c4f9cbc79274d6e46d634d139075492ad055e3d68445925/numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/61.0 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.0/61.0 kB\u001B[0m \u001B[31m9.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting pandas==2.2.3 (from hotel-reservations==0.0.1)\n  Obtaining dependency information for pandas==2.2.3 from https://files.pythonhosted.org/packages/cd/5f/4dba1d39bb9c38d574a9a22548c540177f78ea47b32f99c0ff2ec499fac5/pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/89.9 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m89.9/89.9 kB\u001B[0m \u001B[31m11.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting psutil==6.0.0 (from hotel-reservations==0.0.1)\n  Obtaining dependency information for psutil==6.0.0 from https://files.pythonhosted.org/packages/19/74/f59e7e0d392bc1070e9a70e2f9190d652487ac115bb16e2eff6b22ad1d24/psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nRequirement already satisfied: pyarrow==14.0.1 in /databricks/python3/lib/python3.11/site-packages (from hotel-reservations==0.0.1) (14.0.1)\nCollecting scikit-learn==1.5.2 (from hotel-reservations==0.0.1)\n  Obtaining dependency information for scikit-learn==1.5.2 from https://files.pythonhosted.org/packages/49/21/3723de321531c9745e40f1badafd821e029d346155b6c79704e0b7197552/scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nCollecting lightgbm==4.5.0 (from hotel-reservations==0.0.1)\n  Obtaining dependency information for lightgbm==4.5.0 from https://files.pythonhosted.org/packages/4e/19/1b928cad70a4e1a3e2c37d5417ca2182510f2451eaadb6c91cd9ec692cae/lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl.metadata\n  Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\nCollecting scipy==1.14.1 (from hotel-reservations==0.0.1)\n  Obtaining dependency information for scipy==1.14.1 from https://files.pythonhosted.org/packages/93/6b/701776d4bd6bdd9b629c387b5140f006185bd8ddea16788a44434376b98f/scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/60.8 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m60.8/60.8 kB\u001B[0m \u001B[31m10.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting databricks-feature-engineering==0.6 (from hotel-reservations==0.0.1)\n  Obtaining dependency information for databricks-feature-engineering==0.6 from https://files.pythonhosted.org/packages/ae/73/ab301d1b538014c91fc4481b7e13c374cc60dd2cb0c0ea0ebf36a3f789c6/databricks_feature_engineering-0.6.0-py3-none-any.whl.metadata\n  Downloading databricks_feature_engineering-0.6.0-py3-none-any.whl.metadata (4.2 kB)\nCollecting databricks-feature-lookup==1.2.0 (from hotel-reservations==0.0.1)\n  Obtaining dependency information for databricks-feature-lookup==1.2.0 from https://files.pythonhosted.org/packages/20/16/d5464c1d6a11896d956dd9b9854c7072ca87333a8d788e3bd176b062bcf5/databricks_feature_lookup-1.2.0-py3-none-any.whl.metadata\n  Downloading databricks_feature_lookup-1.2.0-py3-none-any.whl.metadata (4.5 kB)\nCollecting databricks-sdk==0.32.0 (from hotel-reservations==0.0.1)\n  Obtaining dependency information for databricks-sdk==0.32.0 from https://files.pythonhosted.org/packages/b5/a7/0f7ce505b256c4b25bd9ce2ffc4304a77e78f933e942d80f11809e2b0a28/databricks_sdk-0.32.0-py3-none-any.whl.metadata\n  Downloading databricks_sdk-0.32.0-py3-none-any.whl.metadata (37 kB)\nCollecting pydantic==2.9.2 (from hotel-reservations==0.0.1)\n  Obtaining dependency information for pydantic==2.9.2 from https://files.pythonhosted.org/packages/df/e4/ba44652d562cbf0bf320e0f3810206149c8a4e99cdbf66da82e97ab53a15/pydantic-2.9.2-py3-none-any.whl.metadata\n  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/149.4 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m149.4/149.4 kB\u001B[0m \u001B[31m15.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting loguru==0.7.3 (from hotel-reservations==0.0.1)\n  Obtaining dependency information for loguru==0.7.3 from https://files.pythonhosted.org/packages/0c/29/0348de65b8cc732daa3e33e67806420b2ae89bdce2b04af740289c5c6c8c/loguru-0.7.3-py3-none-any.whl.metadata\n  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.11/site-packages (from cffi==1.17.1->hotel-reservations==0.0.1) (2.21)\nRequirement already satisfied: mlflow-skinny[databricks]<3,>=2.11.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->hotel-reservations==0.0.1) (2.11.4)\nRequirement already satisfied: pyyaml<7,>=6 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->hotel-reservations==0.0.1) (6.0)\nRequirement already satisfied: boto3<2,>=1.16.7 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->hotel-reservations==0.0.1) (1.34.39)\nCollecting dbl-tempo<1,>=0.1.26 (from databricks-feature-engineering==0.6->hotel-reservations==0.0.1)\n  Obtaining dependency information for dbl-tempo<1,>=0.1.26 from https://files.pythonhosted.org/packages/1a/66/18cab25fbffe683e336add1279e7b7fc4b2d2509d56aaf782f36838df0b5/dbl_tempo-0.1.29-py3-none-any.whl.metadata\n  Downloading dbl_tempo-0.1.29-py3-none-any.whl.metadata (11 kB)\nCollecting azure-cosmos==4.3.1 (from databricks-feature-engineering==0.6->hotel-reservations==0.0.1)\n  Obtaining dependency information for azure-cosmos==4.3.1 from https://files.pythonhosted.org/packages/1a/e6/8fdeb60b1a5d2a9128a038056acaca64ee87a68cbe2f18dfe8a91cb4e5c2/azure_cosmos-4.3.1-py3-none-any.whl.metadata\n  Downloading azure_cosmos-4.3.1-py3-none-any.whl.metadata (52 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/52.4 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m52.4/52.4 kB\u001B[0m \u001B[31m7.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->hotel-reservations==0.0.1) (4.24.1)\nCollecting flask<3,>=1.1.2 (from databricks-feature-engineering==0.6->hotel-reservations==0.0.1)\n  Obtaining dependency information for flask<3,>=1.1.2 from https://files.pythonhosted.org/packages/fd/56/26f0be8adc2b4257df20c1c4260ddd0aa396cf8e75d90ab2f7ff99bc34f9/flask-2.3.3-py3-none-any.whl.metadata\n  Downloading flask-2.3.3-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->hotel-reservations==0.0.1) (0.5.0)\nCollecting sqlalchemy>=1.4.8 (from databricks-feature-lookup==1.2.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for sqlalchemy>=1.4.8 from https://files.pythonhosted.org/packages/62/e4/b9a7a0e5c6f79d49bcd6efb6e90d7536dc604dab64582a9dec220dab54b6/sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\nCollecting pymysql>=1.0.2 (from databricks-feature-lookup==1.2.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for pymysql>=1.0.2 from https://files.pythonhosted.org/packages/0c/94/e4181a1f6286f545507528c78016e00065ea913276888db2262507693ce5/PyMySQL-1.1.1-py3-none-any.whl.metadata\n  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: requests==2.* in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-lookup==1.2.0->hotel-reservations==0.0.1) (2.31.0)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk==0.32.0->hotel-reservations==0.0.1) (2.31.0)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->hotel-reservations==0.0.1) (1.0.5)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->hotel-reservations==0.0.1) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->hotel-reservations==0.0.1) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->hotel-reservations==0.0.1) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->hotel-reservations==0.0.1) (23.2)\nRequirement already satisfied: pillow>=8 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->hotel-reservations==0.0.1) (9.4.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->hotel-reservations==0.0.1) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->hotel-reservations==0.0.1) (2.8.2)\nCollecting mlflow-skinny==2.17.0 (from mlflow==2.17.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for mlflow-skinny==2.17.0 from https://files.pythonhosted.org/packages/a3/35/2821869a7c78e50148e460406834c4d8aa863d361b7084a8e923f18be474/mlflow_skinny-2.17.0-py3-none-any.whl.metadata\n  Downloading mlflow_skinny-2.17.0-py3-none-any.whl.metadata (30 kB)\nCollecting alembic!=1.10.0,<2 (from mlflow==2.17.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for alembic!=1.10.0,<2 from https://files.pythonhosted.org/packages/31/59/565286efff3692c5716c212202af61466480f6357c4ae3089d4453bff1f3/alembic-1.16.1-py3-none-any.whl.metadata\n  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\nCollecting docker<8,>=4.0.0 (from mlflow==2.17.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for docker<8,>=4.0.0 from https://files.pythonhosted.org/packages/e3/26/57c6fb270950d476074c087527a558ccb6f4436657314bfb6cdf484114c4/docker-7.1.0-py3-none-any.whl.metadata\n  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting graphene<4 (from mlflow==2.17.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for graphene<4 from https://files.pythonhosted.org/packages/66/e0/61d8e98007182e6b2aca7cf65904721fb2e4bce0192272ab9cb6f69d8812/graphene-3.4.3-py2.py3-none-any.whl.metadata\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting markdown<4,>=3.3 (from mlflow==2.17.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for markdown<4,>=3.3 from https://files.pythonhosted.org/packages/51/3f/afe76f8e2246ffbc867440cbcf90525264df0e658f8a5ca1f872b3f6192a/markdown-3.8-py3-none-any.whl.metadata\n  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\nCollecting Jinja2<4,>=2.11 (from mlflow==2.17.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for Jinja2<4,>=2.11 from https://files.pythonhosted.org/packages/62/a1/3d680cbfd5f4b8f15abc1d571870c5fc3e594bb582bc3b64ea099db13e56/jinja2-3.1.6-py3-none-any.whl.metadata\n  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\nCollecting gunicorn<24 (from mlflow==2.17.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for gunicorn<24 from https://files.pythonhosted.org/packages/cb/7d/6dac2a6e1eba33ee43f318edbed4ff29151a49b5d37f080aad1e6469bca4/gunicorn-23.0.0-py3-none-any.whl.metadata\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas==2.2.3->hotel-reservations==0.0.1) (2022.7)\nCollecting tzdata>=2022.7 (from pandas==2.2.3->hotel-reservations==0.0.1)\n  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/5c/23/c7abc0ca0a1526a0774eca151daeb8de62ec457e77262b66b359c3c7679e/tzdata-2025.2-py2.py3-none-any.whl.metadata\n  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting annotated-types>=0.6.0 (from pydantic==2.9.2->hotel-reservations==0.0.1)\n  Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\nCollecting pydantic-core==2.23.4 (from pydantic==2.9.2->hotel-reservations==0.0.1)\n  Obtaining dependency information for pydantic-core==2.23.4 from https://files.pythonhosted.org/packages/44/31/a3899b5ce02c4316865e390107f145089876dff7e1dfc770a231d836aed8/pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: typing-extensions>=4.6.1 in /databricks/python3/lib/python3.11/site-packages (from pydantic==2.9.2->hotel-reservations==0.0.1) (4.10.0)\nRequirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn==1.5.2->hotel-reservations==0.0.1) (1.2.0)\nCollecting threadpoolctl>=3.1.0 (from scikit-learn==1.5.2->hotel-reservations==0.0.1)\n  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl.metadata\n  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: azure-core<2.0.0,>=1.23.0 in /databricks/python3/lib/python3.11/site-packages (from azure-cosmos==4.3.1->databricks-feature-engineering==0.6->hotel-reservations==0.0.1) (1.30.2)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->hotel-reservations==0.0.1) (5.3.3)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->hotel-reservations==0.0.1) (8.0.4)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->hotel-reservations==0.0.1) (3.1.43)\nRequirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->hotel-reservations==0.0.1) (6.0.0)\nCollecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.17.0->mlflow==2.17.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for opentelemetry-api<3,>=1.9.0 from https://files.pythonhosted.org/packages/98/f9/d50ba0c92a97a6d0861357d0ecd67e850d319ac7e7be1895cc236b6ed2b5/opentelemetry_api-1.34.0-py3-none-any.whl.metadata\n  Downloading opentelemetry_api-1.34.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.17.0->mlflow==2.17.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for opentelemetry-sdk<3,>=1.9.0 from https://files.pythonhosted.org/packages/55/96/5b788eef90a65543a67988729f0e44fc46eac1da455505ae5091f418a9d9/opentelemetry_sdk-1.34.0-py3-none-any.whl.metadata\n  Downloading opentelemetry_sdk-1.34.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup==1.2.0->hotel-reservations==0.0.1) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup==1.2.0->hotel-reservations==0.0.1) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup==1.2.0->hotel-reservations==0.0.1) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup==1.2.0->hotel-reservations==0.0.1) (2023.7.22)\nCollecting Mako (from alembic!=1.10.0,<2->mlflow==2.17.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for Mako from https://files.pythonhosted.org/packages/87/fb/99f81ac72ae23375f22b7afdb7642aba97c00a713c217124420147681a2f/mako-1.3.10-py3-none-any.whl.metadata\n  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\nCollecting typing-extensions>=4.6.1 (from pydantic==2.9.2->hotel-reservations==0.0.1)\n  Obtaining dependency information for typing-extensions>=4.6.1 from https://files.pythonhosted.org/packages/69/e0/552843e0d356fbb5256d21449fa957fa4eff3bbc135a74a691ee70c7c5da/typing_extensions-4.14.0-py3-none-any.whl.metadata\n  Downloading typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: botocore<1.35.0,>=1.34.39 in /databricks/python3/lib/python3.11/site-packages (from boto3<2,>=1.16.7->databricks-feature-engineering==0.6->hotel-reservations==0.0.1) (1.34.39)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.11/site-packages (from boto3<2,>=1.16.7->databricks-feature-engineering==0.6->hotel-reservations==0.0.1) (0.10.0)\nRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /databricks/python3/lib/python3.11/site-packages (from boto3<2,>=1.16.7->databricks-feature-engineering==0.6->hotel-reservations==0.0.1) (0.10.2)\nCollecting Werkzeug>=2.3.7 (from flask<3,>=1.1.2->databricks-feature-engineering==0.6->hotel-reservations==0.0.1)\n  Obtaining dependency information for Werkzeug>=2.3.7 from https://files.pythonhosted.org/packages/52/24/ab44c871b0f07f491e5d2ad12c9bd7358e527510618cb1b803a88e986db1/werkzeug-3.1.3-py3-none-any.whl.metadata\n  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\nCollecting itsdangerous>=2.1.2 (from flask<3,>=1.1.2->databricks-feature-engineering==0.6->hotel-reservations==0.0.1)\n  Obtaining dependency information for itsdangerous>=2.1.2 from https://files.pythonhosted.org/packages/04/96/92447566d16df59b2a776c0fb82dbc4d9e07cd95062562af01e408583fc4/itsdangerous-2.2.0-py3-none-any.whl.metadata\n  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\nCollecting click<9,>=7.0 (from mlflow-skinny==2.17.0->mlflow==2.17.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for click<9,>=7.0 from https://files.pythonhosted.org/packages/85/32/10bb5764d90a8eee674e9dc6f4db6a0ab47c8c4d0d83c27f7c39ac415a4d/click-8.2.1-py3-none-any.whl.metadata\n  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\nCollecting blinker>=1.6.2 (from flask<3,>=1.1.2->databricks-feature-engineering==0.6->hotel-reservations==0.0.1)\n  Obtaining dependency information for blinker>=1.6.2 from https://files.pythonhosted.org/packages/10/cb/f2ad4230dc2eb1a74edf38f1a38b9b52277f75bef262d8908e60d957e13c/blinker-1.9.0-py3-none-any.whl.metadata\n  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk==0.32.0->hotel-reservations==0.0.1) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk==0.32.0->hotel-reservations==0.0.1) (4.9)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow==2.17.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for graphql-core<3.3,>=3.1 from https://files.pythonhosted.org/packages/ae/4f/7297663840621022bc73c22d7d9d80dbc78b4db6297f764b545cd5dd462d/graphql_core-3.2.6-py3-none-any.whl.metadata\n  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow==2.17.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for graphql-relay<3.3,>=3.1 from https://files.pythonhosted.org/packages/74/16/a4cf06adbc711bd364a73ce043b0b08d8fa5aae3df11b6ee4248bcdad2e0/graphql_relay-3.2.0-py3-none-any.whl.metadata\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nCollecting MarkupSafe>=2.0 (from Jinja2<4,>=2.11->mlflow==2.17.0->hotel-reservations==0.0.1)\n  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/f1/a4/aefb044a2cd8d7334c8a47d3fb2c9f328ac48cb349468cc31c20b539305f/MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nINFO: pip is looking at multiple versions of mlflow-skinny[databricks] to determine which version is compatible with other requirements. This could take a while.\nCollecting mlflow-skinny[databricks]<3,>=2.11.0 (from databricks-feature-engineering==0.6->hotel-reservations==0.0.1)\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/75/da/8f77cbbd6c5f38a295d1ad2bc58805bd789fabd24d6d482b2aa19e9eb9fd/mlflow_skinny-2.22.1-py3-none-any.whl.metadata\n  Downloading mlflow_skinny-2.22.1-py3-none-any.whl.metadata (31 kB)\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/f4/eb/53dd2a5db1040a21da2980c382ebe3a9bda2d8af8365c2d01053c924b150/mlflow_skinny-2.22.0-py3-none-any.whl.metadata\n  Downloading mlflow_skinny-2.22.0-py3-none-any.whl.metadata (31 kB)\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/2d/f8/b71f88ca373f248fd7fd\n\n*** WARNING: max output size exceeded, skipping output. ***\n\nment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b\n    Can't uninstall 'scipy'. No files were found to uninstall.\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.5.3\n    Not uninstalling pandas at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b\n    Can't uninstall 'pandas'. No files were found to uninstall.\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.3.0\n    Not uninstalling scikit-learn at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b\n    Can't uninstall 'scikit-learn'. No files were found to uninstall.\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 1.10.6\n    Not uninstalling pydantic at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b\n    Can't uninstall 'pydantic'. No files were found to uninstall.\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.2\n    Not uninstalling matplotlib at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b\n    Can't uninstall 'matplotlib'. No files were found to uninstall.\n  Attempting uninstall: databricks-sdk\n    Found existing installation: databricks-sdk 0.20.0\n    Not uninstalling databricks-sdk at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b\n    Can't uninstall 'databricks-sdk'. No files were found to uninstall.\n  Attempting uninstall: mlflow-skinny\n    Found existing installation: mlflow-skinny 2.11.4\n    Not uninstalling mlflow-skinny at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b\n    Can't uninstall 'mlflow-skinny'. No files were found to uninstall.\nSuccessfully installed Jinja2-3.1.6 Mako-1.3.10 MarkupSafe-3.0.2 Werkzeug-3.1.3 alembic-1.16.1 annotated-types-0.7.0 azure-cosmos-4.3.1 blinker-1.9.0 cffi-1.17.1 click-8.2.1 cloudpickle-3.1.0 databricks-feature-engineering-0.6.0 databricks-feature-lookup-1.2.0 databricks-sdk-0.32.0 dbl-tempo-0.1.29 docker-7.1.0 flask-2.3.3 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 greenlet-3.2.3 gunicorn-23.0.0 hotel-reservations-0.0.1 itsdangerous-2.2.0 lightgbm-4.5.0 loguru-0.7.3 markdown-3.8 matplotlib-3.9.2 mlflow-2.17.0 mlflow-skinny-2.17.0 numpy-1.26.4 opentelemetry-api-1.34.0 opentelemetry-sdk-1.34.0 opentelemetry-semantic-conventions-0.55b0 pandas-2.2.3 psutil-6.0.0 pydantic-2.9.2 pydantic-core-2.23.4 pymysql-1.1.1 scikit-learn-1.5.2 scipy-1.14.1 sqlalchemy-2.0.41 threadpoolctl-3.6.0 typing-extensions-4.14.0 tzdata-2025.2\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting git+https://github.com/end-to-end-mlops-databricks-3/marvelous@0.1.0\n  Cloning https://github.com/end-to-end-mlops-databricks-3/marvelous (to revision 0.1.0) to /tmp/pip-req-build-sf0lg5b7\n  Running command git clone --filter=blob:none --quiet https://github.com/end-to-end-mlops-databricks-3/marvelous /tmp/pip-req-build-sf0lg5b7\n  Running command git checkout -q 7fc6264a3f6c1401662fa2ce0d31972b50d0d0fb\n  Resolved https://github.com/end-to-end-mlops-databricks-3/marvelous to commit 7fc6264a3f6c1401662fa2ce0d31972b50d0d0fb\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Installing backend dependencies: started\n  Installing backend dependencies: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nCollecting requests>=2.32.3 (from marvelous==0.1.0)\n  Obtaining dependency information for requests>=2.32.3 from https://files.pythonhosted.org/packages/7c/e4/56027c4a6b4ae70ca9de302488c5ca95ad4a39e190093d6c1a8ace08341b/requests-2.32.4-py3-none-any.whl.metadata\n  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: loguru==0.7.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from marvelous==0.1.0) (0.7.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.32.3->marvelous==0.1.0) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.32.3->marvelous==0.1.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.32.3->marvelous==0.1.0) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.32.3->marvelous==0.1.0) (2023.7.22)\nDownloading requests-2.32.4-py3-none-any.whl (64 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/64.8 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m64.8/64.8 kB\u001B[0m \u001B[31m2.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hBuilding wheels for collected packages: marvelous\n  Building wheel for marvelous (pyproject.toml): started\n  Building wheel for marvelous (pyproject.toml): finished with status 'done'\n  Created wheel for marvelous: filename=marvelous-0.1.0-py3-none-any.whl size=5788 sha256=810b527013b3182904fb8e71cfb43a8b420a8e91f8d996a257ce9bc2169e3a9b\n  Stored in directory: /tmp/pip-ephem-wheel-cache-22tsszha/wheels/5d/57/73/b648ba8e04db42ae5b40d91c83e810124ec16d8961a9859aa4\nSuccessfully built marvelous\nInstalling collected packages: requests, marvelous\n  Attempting uninstall: requests\n    Found existing installation: requests 2.31.0\n    Not uninstalling requests at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b\n    Can't uninstall 'requests'. No files were found to uninstall.\nSuccessfully installed marvelous-0.1.0 requests-2.32.4\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting python-dotenv\n  Obtaining dependency information for python-dotenv from https://files.pythonhosted.org/packages/1e/18/98a99ad95133c6a6e2005fe89faedf294a748bd5dc803008059409ac9b1e/python_dotenv-1.1.0-py3-none-any.whl.metadata\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nInstalling collected packages: python-dotenv\nSuccessfully installed python-dotenv-1.1.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: databricks-feature-engineering in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (0.6.0)\nRequirement already satisfied: databricks-feature-lookup in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (1.2.0)\nRequirement already satisfied: mlflow-skinny[databricks]<3,>=2.11.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from databricks-feature-engineering) (2.17.0)\nRequirement already satisfied: pyyaml<7,>=6 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering) (6.0)\nRequirement already satisfied: boto3<2,>=1.16.7 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering) (1.34.39)\nRequirement already satisfied: dbl-tempo<1,>=0.1.26 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from databricks-feature-engineering) (0.1.29)\nRequirement already satisfied: azure-cosmos==4.3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from databricks-feature-engineering) (4.3.1)\nRequirement already satisfied: numpy<2,>=1.19.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from databricks-feature-engineering) (1.26.4)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering) (4.24.1)\nRequirement already satisfied: flask<3,>=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from databricks-feature-engineering) (2.3.3)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering) (0.5.0)\nRequirement already satisfied: azure-core<2.0.0,>=1.23.0 in /databricks/python3/lib/python3.11/site-packages (from azure-cosmos==4.3.1->databricks-feature-engineering) (1.30.2)\nRequirement already satisfied: mlflow>=1.23.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from databricks-feature-lookup) (2.17.0)\nRequirement already satisfied: sqlalchemy>=1.4.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from databricks-feature-lookup) (2.0.41)\nRequirement already satisfied: pymysql>=1.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from databricks-feature-lookup) (1.1.1)\nRequirement already satisfied: pyarrow==14.* in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-lookup) (14.0.1)\nRequirement already satisfied: requests==2.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from databricks-feature-lookup) (2.32.4)\nRequirement already satisfied: charset_normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup) (2023.7.22)\nRequirement already satisfied: botocore<1.35.0,>=1.34.39 in /databricks/python3/lib/python3.11/site-packages (from boto3<2,>=1.16.7->databricks-feature-engineering) (1.34.39)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.11/site-packages (from boto3<2,>=1.16.7->databricks-feature-engineering) (0.10.0)\nRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /databricks/python3/lib/python3.11/site-packages (from boto3<2,>=1.16.7->databricks-feature-engineering) (0.10.2)\nRequirement already satisfied: Werkzeug>=2.3.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from flask<3,>=1.1.2->databricks-feature-engineering) (3.1.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from flask<3,>=1.1.2->databricks-feature-engineering) (3.1.6)\nRequirement already satisfied: itsdangerous>=2.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from flask<3,>=1.1.2->databricks-feature-engineering) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from flask<3,>=1.1.2->databricks-feature-engineering) (8.2.1)\nRequirement already satisfied: blinker>=1.6.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from flask<3,>=1.1.2->databricks-feature-engineering) (1.9.0)\nRequirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from mlflow>=1.23.0->databricks-feature-lookup) (1.16.1)\nRequirement already satisfied: docker<8,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from mlflow>=1.23.0->databricks-feature-lookup) (7.1.0)\nRequirement already satisfied: graphene<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from mlflow>=1.23.0->databricks-feature-lookup) (3.4.3)\nRequirement already satisfied: markdown<4,>=3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from mlflow>=1.23.0->databricks-feature-lookup) (3.8)\nRequirement already satisfied: matplotlib<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from mlflow>=1.23.0->databricks-feature-lookup) (3.9.2)\nRequirement already satisfied: pandas<3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from mlflow>=1.23.0->databricks-feature-lookup) (2.2.3)\nRequirement already satisfied: scikit-learn<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from mlflow>=1.23.0->databricks-feature-lookup) (1.5.2)\nRequirement already satisfied: scipy<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from mlflow>=1.23.0->databricks-feature-lookup) (1.14.1)\nRequirement already satisfied: gunicorn<24 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from mlflow>=1.23.0->databricks-feature-lookup) (23.0.0)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (5.3.3)\nRequirement already satisfied: cloudpickle<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (3.1.0)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (0.32.0)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (3.1.43)\nRequirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (6.0.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (1.34.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (1.34.0)\nRequirement already satisfied: packaging<25 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (23.2)\nRequirement already satisfied: azure-storage-file-datalake>12 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (12.14.0)\nRequirement already satisfied: google-cloud-storage>=1.30.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (2.17.0)\nRequirement already satisfied: greenlet>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from sqlalchemy>=1.4.8->databricks-feature-lookup) (3.2.3)\nRequirement already satisfied: typing-extensions>=4.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from sqlalchemy>=1.4.8->databricks-feature-lookup) (4.14.0)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow>=1.23.0->databricks-feature-lookup) (1.3.10)\nRequirement already satisfied: six>=1.11.0 in /usr/lib/python3/dist-packages (from azure-core<2.0.0,>=1.23.0->azure-cosmos==4.3.1->databricks-feature-engineering) (1.16.0)\nRequirement already satisfied: azure-storage-blob<13.0.0,>=12.19.0 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (12.19.1)\nRequirement already satisfied: isodate>=0.6.1 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (0.6.1)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /databricks/python3/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.39->boto3<2,>=1.16.7->databricks-feature-engineering) (2.8.2)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (2.31.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (4.0.11)\nRequirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (2.18.0)\nRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (2.4.1)\nRequirement already satisfied: google-resumable-media>=2.6.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (2.7.1)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (1.5.0)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from graphene<4->mlflow>=1.23.0->databricks-feature-lookup) (3.2.6)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from graphene<4->mlflow>=1.23.0->databricks-feature-lookup) (3.2.0)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (3.11.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from Jinja2>=3.1.2->flask<3,>=1.1.2->databricks-feature-engineering) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=1.23.0->databricks-feature-lookup) (1.0.5)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=1.23.0->databricks-feature-lookup) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=1.23.0->databricks-feature-lookup) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=1.23.0->databricks-feature-lookup) (1.4.4)\nRequirement already satisfied: pillow>=8 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=1.23.0->databricks-feature-lookup) (9.4.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=1.23.0->databricks-feature-lookup) (3.0.9)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.55b0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (0.55b0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas<3->mlflow>=1.23.0->databricks-feature-lookup) (2022.7)\nRequirement already satisfied: tzdata>=2022.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from pandas<3->mlflow>=1.23.0->databricks-feature-lookup) (2025.2)\nRequirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow>=1.23.0->databricks-feature-lookup) (1.2.0)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from scikit-learn<2->mlflow>=1.23.0->databricks-feature-lookup) (3.6.0)\nRequirement already satisfied: cryptography>=2.1.4 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (41.0.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (5.0.1)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /databricks/python3/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=1.30.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (1.63.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /databricks/python3/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=1.30.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (1.24.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (4.9)\nRequirement already satisfied: cffi>=1.12 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages (from cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (1.17.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (0.4.8)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering) (2.21)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "%pip install -e ..\n",
    "%pip install git+https://github.com/end-to-end-mlops-databricks-3/marvelous@0.1.0\n",
    "%pip install python-dotenv\n",
    "%pip install databricks-feature-engineering databricks-feature-lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5afea06-0964-4976-983f-ad4739646150",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#restart python\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "792d4c0a-95cb-4deb-868b-f4f7a62b7c11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# system path update, must be after %restart_python\n",
    "# caution! This is not a great approach\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21bf03d5-e6c5-45df-a7d3-cd59e5930899",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# A better approach (this file must be present in a notebook folder, achieved via synchronization)\n",
    "# %pip install hotel_reservation-1.0.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e1dbf08-5727-4a6c-bfa0-6f4d43c55125",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import mlflow\n",
    "\n",
    "from hotel_reservations.config import ProjectConfig\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from mlflow.models import infer_signature\n",
    "from marvelous.common import is_databricks\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from mlflow import MlflowClient\n",
    "import pandas as pd\n",
    "from hotel_reservations import __version__\n",
    "from mlflow.utils.environment import _mlflow_conda_env\n",
    "from databricks import feature_engineering\n",
    "from databricks.feature_engineering import FeatureFunction, FeatureLookup\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "from pyspark.errors import AnalysisException\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "615386b2-8013-4f0c-9ea2-afb796d6502a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not is_databricks():\n",
    "    load_dotenv()\n",
    "    profile = os.environ[\"PROFILE\"]\n",
    "    mlflow.set_tracking_uri(f\"databricks://{profile}\")\n",
    "    mlflow.set_registry_uri(f\"databricks-uc://{profile}\")\n",
    "\n",
    "\n",
    "config = ProjectConfig.from_yaml(config_path=\"../project_config.yml\", env=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ac4c5cc-010e-4af6-acc5-d54e4d76e3ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlops_dev\ngiridhar\n"
     ]
    }
   ],
   "source": [
    "print(config.catalog_name)\n",
    "print(config.schema_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f927160e-7577-4dbd-92e8-5318ea6b229f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "fe = feature_engineering.FeatureEngineeringClient()\n",
    "\n",
    "train_set = spark.table(f\"{config.catalog_name}.{config.schema_name}.train_set\")\n",
    "test_set = spark.table(f\"{config.catalog_name}.{config.schema_name}.test_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03dc3a6a-28a5-47ef-82a8-33faacab1038",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[type_of_meal_plan: string, required_car_parking_space: bigint, room_type_reserved: string, market_segment_type: string, no_of_adults: bigint, no_of_children: bigint, no_of_weekend_nights: bigint, no_of_week_nights: bigint, lead_time: bigint, repeated_guest: bigint, no_of_previous_cancellations: bigint, no_of_previous_bookings_not_canceled: bigint, avg_price_per_room: double, no_of_special_requests: bigint, arrival_date: bigint, arrival_year: bigint, arrival_month: bigint, booking_status: string, Booking_ID: string, month_as_sin: double, month_as_cos: double, update_timestamp_utc: timestamp]\nDataFrame[type_of_meal_plan: string, required_car_parking_space: bigint, room_type_reserved: string, market_segment_type: string, no_of_adults: bigint, no_of_children: bigint, no_of_weekend_nights: bigint, no_of_week_nights: bigint, lead_time: bigint, repeated_guest: bigint, no_of_previous_cancellations: bigint, no_of_previous_bookings_not_canceled: bigint, avg_price_per_room: double, no_of_special_requests: bigint, arrival_date: bigint, arrival_year: bigint, arrival_month: bigint, booking_status: string, Booking_ID: string, month_as_sin: double, month_as_cos: double, update_timestamp_utc: timestamp]\n"
     ]
    }
   ],
   "source": [
    "print(train_set)\n",
    "print(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdaac44e-021c-4f85-b2e2-0e22fae3097f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create feature table with information about houses\n",
    "\n",
    "feature_table_name = f\"{config.catalog_name}.{config.schema_name}.giridhar_hotres_features_demo\"\n",
    "lookup_features = [\"type_of_meal_plan\", \"required_car_parking_space\", \"room_type_reserved\", \"market_segment_type\", \"no_of_adults\", \"no_of_children\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45af6489-2aa5-4eab-a0a6-9025cc3ce8a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = test_set.select(\"Booking_ID\", *lookup_features)\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a705930-3823-47a5-b1e9-c553a6b1a825",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Option 1: feature engineering client\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "feature_table = fe.create_table(\n",
    "   name=feature_table_name,\n",
    "   primary_keys=[\"Booking_ID\"],\n",
    "   df=train_set[[\"Booking_ID\"]+lookup_features],\n",
    "   description=\"Hotel Reservations features table\",\n",
    ")\n",
    "\n",
    "spark.sql(f\"ALTER TABLE {feature_table_name} SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\")\n",
    "\n",
    "int_cols = [\"required_car_parking_space\", \"no_of_adults\", \"no_of_children\"]\n",
    "df = test_set.select(\"Booking_ID\", *lookup_features)\n",
    "for c in int_cols:\n",
    "    df = df.withColumn(c, col(c).cast(IntegerType()))\n",
    "\n",
    "fe.write_table(\n",
    "   name=feature_table_name,\n",
    "   df=df, #test_set[[\"Booking_ID\"]+lookup_features],\n",
    "   mode=\"merge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c320cd00-1029-48d2-8ae4-3a5619ca8303",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.sql(f\"DESCRIBE TABLE {feature_table_name}\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43dabadd-a8b4-4b7e-9fce-bb4eb3ec367e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create feature table with information about houses\n",
    "# Option 2: SQL\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "          CREATE OR REPLACE TABLE {feature_table_name}\n",
    "          (Booking_ID STRING NOT NULL, type_of_meal_plan STRING, required_car_parking_space INT, room_type_reserved STRING, market_segment_type STRING, no_of_adults INT, no_of_children INT);\n",
    "          \"\"\")\n",
    "# primary key on Databricks is not enforced!\n",
    "try:\n",
    "    spark.sql(f\"ALTER TABLE {feature_table_name} ADD CONSTRAINT hotres_pk_demo PRIMARY KEY(Booking_ID);\")\n",
    "except AnalysisException:\n",
    "    pass\n",
    "spark.sql(f\"ALTER TABLE {feature_table_name} SET TBLPROPERTIES (delta.enableChangeDataFeed = true);\")\n",
    "spark.sql(f\"\"\"\n",
    "          INSERT INTO {feature_table_name}\n",
    "          SELECT Booking_ID, type_of_meal_plan, required_car_parking_space, room_type_reserved, market_segment_type, no_of_adults, no_of_children\n",
    "          FROM {config.catalog_name}.{config.schema_name}.train_set\n",
    "          \"\"\")\n",
    "spark.sql(f\"\"\"\n",
    "          INSERT INTO {feature_table_name}\n",
    "          SELECT Booking_ID, type_of_meal_plan, required_car_parking_space, room_type_reserved, market_segment_type, no_of_adults, no_of_children\n",
    "          FROM {config.catalog_name}.{config.schema_name}.test_set\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5291e6c-1cd6-47ea-ab68-2f986f1d195b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create feature function\n",
    "# docs: https://docs.databricks.com/aws/en/sql/language-manual/sql-ref-syntax-ddl-create-sql-function\n",
    "\n",
    "# problems with feature functions:\n",
    "# functions are not versioned \n",
    "# functions may behave differently depending on the runtime (and version of packages and python)\n",
    "# there is no way to enforce python version & package versions for the function \n",
    "# this is only supported from runtime 17\n",
    "# advised to use only for simple calculations\n",
    "\n",
    "function_name = f\"{config.catalog_name}.{config.schema_name}.add_adults_children_demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1e20bd0-2825-4188-951a-36a5b86e75c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Option 1: with Python\n",
    "spark.sql(f\"\"\"\n",
    "        CREATE OR REPLACE FUNCTION {function_name}(no_of_adults INT, no_of_children INT)\n",
    "        RETURNS INT\n",
    "        LANGUAGE PYTHON AS\n",
    "        $$\n",
    "        return no_of_adults + no_of_children\n",
    "        $$\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47291d8a-e2fb-43da-a986-a92faaf2e7e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# it is possible to define simple functions in sql only without python\n",
    "# Option 2\n",
    "# commenting for now\n",
    "# spark.sql(f\"\"\"\n",
    "#         CREATE OR REPLACE FUNCTION {function_name}_sql (no_of_adults INT, no_of_children INT)\n",
    "#         RETURNS INT\n",
    "#         RETURN no_of_adults + no_of_children;\n",
    "#         \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "113f66ab-665c-4e46-a84f-dcd72f01c29d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n|adults_and_childs|\n+-----------------+\n|                8|\n+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# execute function\n",
    "spark.sql(f\"SELECT {function_name}_sql(5, 3) as adults_and_childs;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dff9d1d-e786-4637-89da-1eae5cd0147d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create a training set\n",
    "training_set = fe.create_training_set(\n",
    "    df=train_set.drop(\"type_of_meal_plan\",\n",
    "                      \"required_car_parking_space\",\n",
    "                      \"room_type_reserved\",\n",
    "                      \"market_segment_type\", \n",
    "                      \"no_of_adults\", \n",
    "                      \"no_of_children\"),\n",
    "    label=config.target,\n",
    "    feature_lookups=[\n",
    "        FeatureLookup(\n",
    "            table_name=feature_table_name,\n",
    "            feature_names=[\"type_of_meal_plan\",\n",
    "                            \"required_car_parking_space\",\n",
    "                            \"room_type_reserved\",\n",
    "                            \"market_segment_type\", \n",
    "                            \"no_of_adults\", \n",
    "                            \"no_of_children\"],\n",
    "            lookup_key=\"Booking_ID\",\n",
    "                ),\n",
    "        FeatureFunction(\n",
    "            udf_name=function_name,\n",
    "            output_name=\"adults_and_childs\",\n",
    "            input_bindings={\"no_of_adults\": \"no_of_adults\", \"no_of_children\": \"no_of_children\"},\n",
    "            ),\n",
    "    ],\n",
    "    # exclude_columns=[\"update_timestamp_utc\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9978f90-e995-4b84-81e1-91e035e65b1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train & register a model\n",
    "training_df = training_set.load_df().toPandas()\n",
    "X_train = training_df[config.num_features + config.cat_features + [\"adults_and_childs\"]]\n",
    "y_train = training_df[config.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8029efe-e344-444a-b0a3-f521023658f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>adults_and_childs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_of_adults  no_of_children  adults_and_childs\n",
       "0             2               1                  3\n",
       "1             2               1                  3\n",
       "2             2               0                  2\n",
       "3             2               0                  2\n",
       "4             1               0                  1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['no_of_adults', 'no_of_children', 'adults_and_childs']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbe65a0f-7b52-4953-a2b9-78285c0f97b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 29020 entries, 0 to 29019\nData columns (total 18 columns):\n #   Column                                Non-Null Count  Dtype  \n---  ------                                --------------  -----  \n 0   no_of_adults                          29020 non-null  int32  \n 1   no_of_children                        29020 non-null  int32  \n 2   no_of_weekend_nights                  29020 non-null  int64  \n 3   no_of_week_nights                     29020 non-null  int64  \n 4   lead_time                             29020 non-null  int64  \n 5   repeated_guest                        29020 non-null  int64  \n 6   no_of_previous_cancellations          29020 non-null  int64  \n 7   no_of_previous_bookings_not_canceled  29020 non-null  int64  \n 8   avg_price_per_room                    29020 non-null  float64\n 9   no_of_special_requests                29020 non-null  int64  \n 10  arrival_date                          29020 non-null  int64  \n 11  arrival_year                          29020 non-null  int64  \n 12  arrival_month                         29020 non-null  int64  \n 13  type_of_meal_plan                     29020 non-null  object \n 14  required_car_parking_space            29020 non-null  int32  \n 15  room_type_reserved                    29020 non-null  object \n 16  market_segment_type                   29020 non-null  object \n 17  adults_and_childs                     29020 non-null  int32  \ndtypes: float64(1), int32(4), int64(10), object(3)\nmemory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23b2c995-253f-4640-ac9a-79ea702f9d18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\nRangeIndex: 29020 entries, 0 to 29019\nSeries name: booking_status\nNon-Null Count  Dtype \n--------------  ----- \n29020 non-null  object\ndtypes: object(1)\nmemory usage: 226.8+ KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "424adb04-81a6-479d-b8b0-75a48434ee89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# set the classifier parameters \n",
    "\n",
    "train_parameters = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"max_depth\": 8,\n",
    "    \"num_leaves\": 31,\n",
    "    \"min_child_samples\": 20,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4526e327-c46d-4c41-bef2-26562b6a9e99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19551, number of negative: 9469\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005833 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 669\n[LightGBM] [Info] Number of data points in the train set: 29020, number of used features: 30\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.673708 -> initscore=0.725003\n[LightGBM] [Info] Start training from score 0.725003\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:1623: FutureWarning: \nThe format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\nAt the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\nTo use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;type_of_meal_plan&#x27;,\n",
       "                                                   &#x27;required_car_parking_space&#x27;,\n",
       "                                                   &#x27;room_type_reserved&#x27;,\n",
       "                                                   &#x27;market_segment_type&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LGBMClassifier(colsample_bytree=0.8, max_depth=8,\n",
       "                                n_estimators=1000, random_state=42,\n",
       "                                subsample=0.8))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;type_of_meal_plan&#x27;,\n",
       "                                                   &#x27;required_car_parking_space&#x27;,\n",
       "                                                   &#x27;room_type_reserved&#x27;,\n",
       "                                                   &#x27;market_segment_type&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LGBMClassifier(colsample_bytree=0.8, max_depth=8,\n",
       "                                n_estimators=1000, random_state=42,\n",
       "                                subsample=0.8))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;type_of_meal_plan&#x27;,\n",
       "                                  &#x27;required_car_parking_space&#x27;,\n",
       "                                  &#x27;room_type_reserved&#x27;,\n",
       "                                  &#x27;market_segment_type&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;type_of_meal_plan&#x27;, &#x27;required_car_parking_space&#x27;, &#x27;room_type_reserved&#x27;, &#x27;market_segment_type&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">remainder</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;no_of_adults&#x27;, &#x27;no_of_children&#x27;, &#x27;no_of_weekend_nights&#x27;, &#x27;no_of_week_nights&#x27;, &#x27;lead_time&#x27;, &#x27;repeated_guest&#x27;, &#x27;no_of_previous_cancellations&#x27;, &#x27;no_of_previous_bookings_not_canceled&#x27;, &#x27;avg_price_per_room&#x27;, &#x27;no_of_special_requests&#x27;, &#x27;arrival_date&#x27;, &#x27;arrival_year&#x27;, &#x27;arrival_month&#x27;, &#x27;adults_and_childs&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">passthrough</label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(colsample_bytree=0.8, max_depth=8, n_estimators=1000,\n",
       "               random_state=42, subsample=0.8)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['type_of_meal_plan',\n",
       "                                                   'required_car_parking_space',\n",
       "                                                   'room_type_reserved',\n",
       "                                                   'market_segment_type'])])),\n",
       "                ('classifier',\n",
       "                 LGBMClassifier(colsample_bytree=0.8, max_depth=8,\n",
       "                                n_estimators=1000, random_state=42,\n",
       "                                subsample=0.8))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "        steps=[(\"preprocessor\", ColumnTransformer(\n",
    "            transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "                           config.cat_features)],\n",
    "            remainder=\"passthrough\")\n",
    "            ),\n",
    "               (\"classifier\", LGBMClassifier(**train_parameters))]\n",
    "        )\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1558ec1f-8824-401c-9b41-f51cc84d88ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages/mlflow/types/utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages/mlflow/types/schema.py:679: FutureWarning: `optional` is deprecated and will be removed in a future version of MLflow. Use `required` instead.\n  warnings.warn(\n2025/06/09 17:39:51 INFO mlflow.tracking._tracking_service.client: \uD83C\uDFC3 View run giridhar-hotres-model-fe at: https://dbc-c2e8445d-159d.cloud.databricks.com/ml/experiments/3264736349207955/runs/f7b8a3f538de44a892c182edfe78f8eb.\n2025/06/09 17:39:51 INFO mlflow.tracking._tracking_service.client: \uD83E\uDDEA View experiment at: https://dbc-c2e8445d-159d.cloud.databricks.com/ml/experiments/3264736349207955.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/Shared/giridhar-hotres-model-fe\")\n",
    "with mlflow.start_run(run_name=\"giridhar-hotres-model-fe\",\n",
    "                      tags={\"git_sha\": \"1234567890abcdefg\",\n",
    "                            \"branch\": \"week3\"},\n",
    "                            description=\"demo run for FE model logging\") as run:\n",
    "    # Log parameters and metrics\n",
    "    run_id = run.info.run_id\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM Classifier with preprocessing\")\n",
    "    mlflow.log_params(train_parameters)\n",
    "\n",
    "    # Log the model\n",
    "    signature = infer_signature(model_input=X_train, model_output=pipeline.predict(X_train))\n",
    "    fe.log_model(\n",
    "                model=pipeline,\n",
    "                flavor=mlflow.sklearn,\n",
    "                artifact_path=\"lightgbm-pipeline-model-fe\",\n",
    "                training_set=training_set,\n",
    "                signature=signature,\n",
    "            )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eed8a50-a133-43ad-a087-801d8ee9c0b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'mlops_dev.giridhar.giridhar_hotres_model_fe_demo' already exists. Creating a new version of this model...\nCreated version '23' of model 'mlops_dev.giridhar.giridhar_hotres_model_fe_demo'.\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"{config.catalog_name}.{config.schema_name}.giridhar_hotres_model_fe_demo\"\n",
    "model_version = mlflow.register_model(\n",
    "    model_uri=f'runs:/{run_id}/lightgbm-pipeline-model-fe',\n",
    "    name=model_name,\n",
    "    tags={\"git_sha\": \"1234567890abcdxyz\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "545bc1d3-7348-479f-86fb-a64ca8538dfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no_of_adults', 'no_of_children', 'no_of_weekend_nights', 'no_of_week_nights', 'lead_time', 'repeated_guest', 'no_of_previous_cancellations', 'no_of_previous_bookings_not_canceled', 'avg_price_per_room', 'no_of_special_requests', 'arrival_date', 'arrival_year', 'arrival_month']\n['type_of_meal_plan', 'required_car_parking_space', 'room_type_reserved', 'market_segment_type']\n['type_of_meal_plan', 'required_car_parking_space', 'room_type_reserved', 'market_segment_type', 'no_of_adults', 'no_of_children']\n"
     ]
    }
   ],
   "source": [
    "print(config.num_features)\n",
    "print(config.cat_features)\n",
    "print(lookup_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "058f50bb-fb43-499b-9038-268d81056169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# features = [f for f in [\"Booking_ID\"] + config.num_features + config.cat_features]\n",
    "# features += ['adults_and_childs', \"update_timestamp_utc\", \"month_as_cos\", \"month_as_sin\"]\n",
    "# print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37b03f59-035c-4dce-9667-1ff47c13f159",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 17:39:57 WARNING mlflow.pyfunc: Calling `spark_udf()` with `env_manager=\"local\"` does not recreate the same environment that was used during training, which may lead to errors or inaccurate predictions. We recommend specifying `env_manager=\"conda\"`, which automatically recreates the environment that was used to train the model and performs inference in the recreated environment.\n2025/06/09 17:39:58 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+\n|Booking_ID|prediction_label|\n+----------+----------------+\n|  INN00626|    Not_Canceled|\n|  INN10204|    Not_Canceled|\n|  INN20020|    Not_Canceled|\n|  INN16435|    Not_Canceled|\n|  INN07143|    Not_Canceled|\n+----------+----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, col, when, pandas_udf\n",
    "from pyspark.sql.types import IntegerType, ArrayType, DoubleType, StringType\n",
    "import mlflow.pyfunc\n",
    "\n",
    "\n",
    "# preping the test set\n",
    "test_set = (\n",
    "    test_set\n",
    "      .withColumn(\"no_of_adults\",               col(\"no_of_adults\").cast(IntegerType()))\n",
    "      .withColumn(\"no_of_children\",             col(\"no_of_children\").cast(IntegerType()))\n",
    "      .withColumn(\"required_car_parking_space\", col(\"required_car_parking_space\").cast(IntegerType()))\n",
    "      # .withColumn(\"adults_and_childs\",          col(\"adults_and_childs\").cast(IntegerType()))\n",
    ")\n",
    "\n",
    "\n",
    "test_set = test_set.withColumn(\n",
    "    \"adults_and_childs\",\n",
    "    expr(f\"{config.catalog_name}.{config.schema_name}\"\n",
    "         f\".add_adults_children_demo_sql(no_of_adults, no_of_children)\")\n",
    ")\n",
    "\n",
    "# prepare the features \n",
    "features = [\"Booking_ID\"] + config.num_features + config.cat_features + [\n",
    "    \"update_timestamp_utc\", \"month_as_cos\", \"month_as_sin\", \"adults_and_childs\"\n",
    "]\n",
    "features = [f for f in [\"Booking_ID\"] + config.num_features + config.cat_features if f not in lookup_features]\n",
    "features += [\"update_timestamp_utc\", \"month_as_cos\", \"month_as_sin\"]\n",
    "\n",
    "\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "# Score via FE client, asking for StringType output\n",
    "preds_df = fe.score_batch(\n",
    "    model_uri=f\"models:/{model_name}/{model_version.version}\",\n",
    "    df=test_set.select(*features),\n",
    "    result_type=StringType()\n",
    ")\n",
    "\n",
    "# Rename that “prediction” column to your label\n",
    "preds_labeled = preds_df.withColumnRenamed(\"prediction\", \"prediction_label\")\n",
    "\n",
    "preds_labeled.select(\"Booking_ID\", \"prediction_label\").show(5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # now making the predictions\n",
    "# # because it can only output double, we have to tweak it a little bit\n",
    "# preds_df = fe.score_batch(\n",
    "#     model_uri=f\"models:/{model_name}/{model_version.version}\",\n",
    "#     df=test_set.select(*features)\n",
    "# )\n",
    "\n",
    "# # 2) Convert the `prediction` double into a label\n",
    "# preds_with_label = preds_df.withColumn(\n",
    "#     \"prediction_label\",\n",
    "#     when(col(\"prediction\") >= 0.5, \"1\").otherwise(\"0\")\n",
    "# )\n",
    "\n",
    "# preds_with_label.show(5)\n",
    "\n",
    "# # the below code also proved to be a bit tricky as it had to remove some dependencies\n",
    "# from pyspark.sql.types import StringType  # or IntegerType()\n",
    "# import mlflow.pyfunc\n",
    "\n",
    "# # Create a UDF that returns e.g. String labels\n",
    "# predict_udf = mlflow.pyfunc.spark_udf(\n",
    "#     spark,\n",
    "#     f\"models:/{model_name}/{model_version.version}\",\n",
    "#     result_type=StringType()\n",
    "# )\n",
    "\n",
    "# # Apply it to your feature DataFrame\n",
    "# predictions = test_set.select(\n",
    "#     *features,\n",
    "#     predict_udf(*features).alias(\"prediction\")\n",
    "# )\n",
    "\n",
    "# predictions.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f70c2743-4897-49e5-98fe-2714587e4cb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# predictions = test_set.withColumn(\"prediction\", predict_udf(*features))\n",
    "# predictions.select(\"prediction\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b02734da-8576-455c-b6bb-bf9abd0bbc50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# for me this will also provide an error because since the model is output is a string and fe.client only outputs a double.\n",
    "# predictions.select(\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "118e1383-4667-42b7-9c68-12d89820d0a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 17:40:13 WARNING mlflow.pyfunc: Calling `spark_udf()` with `env_manager=\"local\"` does not recreate the same environment that was used during training, which may lead to errors or inaccurate predictions. We recommend specifying `env_manager=\"conda\"`, which automatically recreates the environment that was used to train the model and performs inference in the recreated environment.\n2025/06/09 17:40:13 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, concat, lit\n",
    "\n",
    "\n",
    "features = [f for f in [\"Booking_ID\"] + config.num_features + config.cat_features if f not in lookup_features]\n",
    "# adding some more features \n",
    "features += [\"update_timestamp_utc\", \"month_as_cos\", \"month_as_sin\"]\n",
    "\n",
    "# # commenting to make a minor change, see the immediate code below \n",
    "# test_set_with_new_id = test_set.select(*features).withColumn(\n",
    "#     \"Booking_ID\",\n",
    "#     (col(\"Booking_ID\").cast(\"long\") + 1000000).cast(\"string\")\n",
    "# )\n",
    "\n",
    "test_set_with_new_id = test_set.select(*features).withColumn(\n",
    "    \"Booking_ID\",\n",
    "    (concat(lit(\"a\"), col(\"Booking_ID\")))\n",
    ")\n",
    "\n",
    "preds_df2 = fe.score_batch(\n",
    "    model_uri=f\"models:/{model_name}/{model_version.version}\",\n",
    "    df=test_set_with_new_id,\n",
    "    result_type=StringType()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0ace606-656d-44a7-bfa1-d501049f59b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# make predictions for a non-existing entry -> error!\n",
    "# preds_df2.select(\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94e8a421-2f0f-42e4-b89b-c52a768ee271",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseadults_function = f\"{config.catalog_name}.{config.schema_name}.base_adults_to_one\"\n",
    "spark.sql(f\"\"\"\n",
    "        CREATE OR REPLACE FUNCTION {baseadults_function}(no_of_adults INT)\n",
    "        RETURNS INT\n",
    "        LANGUAGE PYTHON AS\n",
    "        $$\n",
    "        if no_of_adults is None or no_of_adults == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return no_of_adults\n",
    "        $$\n",
    "        \"\"\")\n",
    "\n",
    "basechilds_function = f\"{config.catalog_name}.{config.schema_name}.base_childs_to_one\"\n",
    "spark.sql(f\"\"\"\n",
    "        CREATE OR REPLACE FUNCTION {basechilds_function}(no_of_children INT)\n",
    "        RETURNS INT\n",
    "        LANGUAGE PYTHON AS\n",
    "        $$\n",
    "        if no_of_children is None or no_of_children == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return no_of_children\n",
    "        $$\n",
    "        \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3323bda8-0bd6-4504-9c2b-f2980080e206",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# what if we want to replace with a default value if entry is not found\n",
    "# what if we want to look up value in another table? the logics get complex\n",
    "# problems that arize: functions/ lookups always get executed (if statememt is not possible)\n",
    "# it can get slow...\n",
    "\n",
    "# step 1: create 3 feature functions\n",
    "\n",
    "# step 2: redefine create training set\n",
    "\n",
    "# try again\n",
    "\n",
    "# create a training set\n",
    "training_set = fe.create_training_set(\n",
    "    df=train_set.drop(\"no_of_adults\", \"no_of_children\"),\n",
    "    label=config.target,\n",
    "    feature_lookups=[\n",
    "        FeatureLookup(\n",
    "            table_name=feature_table_name,\n",
    "            feature_names=[\"no_of_adults\", \"no_of_children\"],\n",
    "            lookup_key=\"Booking_ID\",\n",
    "            rename_outputs={\"no_of_adults\": \"based_adults\",\n",
    "                            \"no_of_children\": \"based_childs\"}\n",
    "                ),\n",
    "        FeatureFunction(\n",
    "            udf_name=baseadults_function,\n",
    "            output_name=\"no_of_adults\",\n",
    "            input_bindings={\"no_of_adults\": \"based_adults\"},\n",
    "            ),\n",
    "        FeatureFunction(\n",
    "            udf_name=basechilds_function,\n",
    "            output_name=\"no_of_children\",\n",
    "            input_bindings={\"no_of_children\": \"based_childs\"},\n",
    "            ),\n",
    "        ],\n",
    "    # exclude_columns=[\"update_timestamp_utc\", \"based_adults\", \"based_childs\"],\n",
    "      )\n",
    "    #     ),\n",
    "    #     FeatureFunction(\n",
    "    #         udf_name=garagecars_function,\n",
    "    #         output_name=\"GarageCars\",\n",
    "    #         input_bindings={\"GarageCars\": \"lookup_GarageCars\"},\n",
    "    #     ),\n",
    "    #     FeatureFunction(\n",
    "    #         udf_name=function_name,\n",
    "    #         output_name=\"house_age\",\n",
    "    #         input_bindings={\"year_built\": \"YearBuilt\"},\n",
    "    #         ),\n",
    "    # ],\n",
    "    # exclude_columns=[\"update_timestamp_utc\"],\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d8fcf07-d3bf-4043-9f7f-89f09c50a71e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Materialize the training set into a Spark DataFrame\n",
    "# ts_df = training_set.load_df()\n",
    "\n",
    "# # 1) Check the schema\n",
    "# ts_df.printSchema()\n",
    "\n",
    "# # 2) Peek at the key columns\n",
    "# ts_df.select(\n",
    "#     \"Booking_ID\",\n",
    "#     \"based_adults\",\n",
    "#     \"based_childs\",\n",
    "#     \"no_of_adults\",\n",
    "#     \"no_of_children\",\n",
    "#     config.target\n",
    "# ).show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee27222d-c0f0-43e9-9260-51b8831d417d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 29020 entries, 0 to 29019\nData columns (total 18 columns):\n #   Column                                Non-Null Count  Dtype  \n---  ------                                --------------  -----  \n 0   no_of_adults                          29020 non-null  int32  \n 1   no_of_children                        29020 non-null  int32  \n 2   no_of_weekend_nights                  29020 non-null  int64  \n 3   no_of_week_nights                     29020 non-null  int64  \n 4   lead_time                             29020 non-null  int64  \n 5   repeated_guest                        29020 non-null  int64  \n 6   no_of_previous_cancellations          29020 non-null  int64  \n 7   no_of_previous_bookings_not_canceled  29020 non-null  int64  \n 8   avg_price_per_room                    29020 non-null  float64\n 9   no_of_special_requests                29020 non-null  int64  \n 10  arrival_date                          29020 non-null  int64  \n 11  arrival_year                          29020 non-null  int64  \n 12  arrival_month                         29020 non-null  int64  \n 13  type_of_meal_plan                     29020 non-null  object \n 14  required_car_parking_space            29020 non-null  int32  \n 15  room_type_reserved                    29020 non-null  object \n 16  market_segment_type                   29020 non-null  object \n 17  adults_and_childs                     29020 non-null  int32  \ndtypes: float64(1), int32(4), int64(10), object(3)\nmemory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb22169d-8270-4ac1-9c35-ad168046bc0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 29020 entries, 0 to 29019\nData columns (total 23 columns):\n #   Column                                Non-Null Count  Dtype         \n---  ------                                --------------  -----         \n 0   no_of_weekend_nights                  29020 non-null  int64         \n 1   no_of_week_nights                     29020 non-null  int64         \n 2   lead_time                             29020 non-null  int64         \n 3   repeated_guest                        29020 non-null  int64         \n 4   no_of_previous_cancellations          29020 non-null  int64         \n 5   no_of_previous_bookings_not_canceled  29020 non-null  int64         \n 6   avg_price_per_room                    29020 non-null  float64       \n 7   no_of_special_requests                29020 non-null  int64         \n 8   arrival_date                          29020 non-null  int64         \n 9   arrival_year                          29020 non-null  int64         \n 10  arrival_month                         29020 non-null  int64         \n 11  Booking_ID                            29020 non-null  object        \n 12  month_as_sin                          29020 non-null  float64       \n 13  month_as_cos                          29020 non-null  float64       \n 14  update_timestamp_utc                  29020 non-null  datetime64[ns]\n 15  type_of_meal_plan                     29020 non-null  object        \n 16  required_car_parking_space            29020 non-null  int32         \n 17  room_type_reserved                    29020 non-null  object        \n 18  market_segment_type                   29020 non-null  object        \n 19  no_of_adults                          29020 non-null  int32         \n 20  no_of_children                        29020 non-null  int32         \n 21  adults_and_childs                     29020 non-null  int32         \n 22  booking_status                        29020 non-null  object        \ndtypes: datetime64[ns](1), float64(3), int32(4), int64(10), object(5)\nmemory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "training_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2df2c17-8fb7-4503-a32b-e921faf570ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19551, number of negative: 9469\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004096 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 662\n[LightGBM] [Info] Number of data points in the train set: 29020, number of used features: 29\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.673708 -> initscore=0.725003\n[LightGBM] [Info] Start training from score 0.725003\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:1623: FutureWarning: \nThe format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\nAt the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\nTo use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;type_of_meal_plan&#x27;,\n",
       "                                                   &#x27;required_car_parking_space&#x27;,\n",
       "                                                   &#x27;room_type_reserved&#x27;,\n",
       "                                                   &#x27;market_segment_type&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LGBMClassifier(colsample_bytree=0.8, max_depth=8,\n",
       "                                n_estimators=1000, random_state=42,\n",
       "                                subsample=0.8))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;type_of_meal_plan&#x27;,\n",
       "                                                   &#x27;required_car_parking_space&#x27;,\n",
       "                                                   &#x27;room_type_reserved&#x27;,\n",
       "                                                   &#x27;market_segment_type&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LGBMClassifier(colsample_bytree=0.8, max_depth=8,\n",
       "                                n_estimators=1000, random_state=42,\n",
       "                                subsample=0.8))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;type_of_meal_plan&#x27;,\n",
       "                                  &#x27;required_car_parking_space&#x27;,\n",
       "                                  &#x27;room_type_reserved&#x27;,\n",
       "                                  &#x27;market_segment_type&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;type_of_meal_plan&#x27;, &#x27;required_car_parking_space&#x27;, &#x27;room_type_reserved&#x27;, &#x27;market_segment_type&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">remainder</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;no_of_weekend_nights&#x27;, &#x27;no_of_week_nights&#x27;, &#x27;lead_time&#x27;, &#x27;repeated_guest&#x27;, &#x27;no_of_previous_cancellations&#x27;, &#x27;no_of_previous_bookings_not_canceled&#x27;, &#x27;avg_price_per_room&#x27;, &#x27;no_of_special_requests&#x27;, &#x27;arrival_date&#x27;, &#x27;arrival_year&#x27;, &#x27;arrival_month&#x27;, &#x27;based_adults&#x27;, &#x27;based_childs&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">passthrough</label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(colsample_bytree=0.8, max_depth=8, n_estimators=1000,\n",
       "               random_state=42, subsample=0.8)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['type_of_meal_plan',\n",
       "                                                   'required_car_parking_space',\n",
       "                                                   'room_type_reserved',\n",
       "                                                   'market_segment_type'])])),\n",
       "                ('classifier',\n",
       "                 LGBMClassifier(colsample_bytree=0.8, max_depth=8,\n",
       "                                n_estimators=1000, random_state=42,\n",
       "                                subsample=0.8))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train & register a model\n",
    "training_df = training_set.load_df().toPandas()\n",
    "num_features_adjusted = config.num_features\n",
    "num_features_adjusted = [feature for feature in num_features_adjusted if feature not in [\"no_of_adults\", \"no_of_children\"]]\n",
    "X_train = training_df[num_features_adjusted + config.cat_features + [\"based_adults\"] + [\"based_childs\"]]\n",
    "y_train = training_df[config.target]\n",
    "\n",
    "#pipeline\n",
    "pipeline = Pipeline(\n",
    "        steps=[(\"preprocessor\", ColumnTransformer(\n",
    "            transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "                           config.cat_features)],\n",
    "            remainder=\"passthrough\")\n",
    "            ),\n",
    "               (\"classifier\", LGBMClassifier(**train_parameters))]\n",
    "        )\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc7fb3f0-a562-4236-a943-058842699226",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ts = training_set.load_df()\n",
    "# ts.printSchema()\n",
    "# ts.select(\"Booking_ID\", \"based_adults\", \"based_childs\", \"no_of_adults\", \"no_of_children\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "602cbd2f-54a0-4280-870d-ee9df0c6afef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 29020 entries, 0 to 29019\nData columns (total 17 columns):\n #   Column                                Non-Null Count  Dtype  \n---  ------                                --------------  -----  \n 0   no_of_weekend_nights                  29020 non-null  int64  \n 1   no_of_week_nights                     29020 non-null  int64  \n 2   lead_time                             29020 non-null  int64  \n 3   repeated_guest                        29020 non-null  int64  \n 4   no_of_previous_cancellations          29020 non-null  int64  \n 5   no_of_previous_bookings_not_canceled  29020 non-null  int64  \n 6   avg_price_per_room                    29020 non-null  float64\n 7   no_of_special_requests                29020 non-null  int64  \n 8   arrival_date                          29020 non-null  int64  \n 9   arrival_year                          29020 non-null  int64  \n 10  arrival_month                         29020 non-null  int64  \n 11  type_of_meal_plan                     29020 non-null  object \n 12  required_car_parking_space            29020 non-null  int64  \n 13  room_type_reserved                    29020 non-null  object \n 14  market_segment_type                   29020 non-null  object \n 15  based_adults                          29020 non-null  int32  \n 16  based_childs                          29020 non-null  int32  \ndtypes: float64(1), int32(2), int64(11), object(3)\nmemory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# just checking X_train\n",
    "\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fb431ed-0f99-4dbc-a033-14d4fa83f21f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing in FE pipeline: set()\nExtra    in FE pipeline: {'no_of_children', 'no_of_adults'}\n"
     ]
    }
   ],
   "source": [
    "# 1) The list of feature columns your model was trained on\n",
    "train_feats = set(X_train.columns)\n",
    "\n",
    "# 2) The columns emitted by your FE pipeline (which includes extra columns like label and metadata)\n",
    "all_columns = set(training_set.load_df().columns)\n",
    "\n",
    "# 3) Columns you need to ignore when comparing\n",
    "to_ignore = {\n",
    "    config.target,            # booking_status label\n",
    "    \"Booking_ID\",             # just an ID, not a model input\n",
    "    \"update_timestamp_utc\",   # time metadata\n",
    "    \"month_as_sin\",           # these came from your feature script, but not in X_train\n",
    "    \"month_as_cos\"\n",
    "}\n",
    "\n",
    "# 4) Compute the actual FE-produced feature set\n",
    "fe_produced_feats = all_columns - to_ignore\n",
    "\n",
    "missing = train_feats - fe_produced_feats\n",
    "extra   = fe_produced_feats - train_feats\n",
    "\n",
    "print(\"Missing in FE pipeline:\", missing)\n",
    "print(\"Extra    in FE pipeline:\", extra)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f66b6e6-c3b5-493d-ba0d-0eb3cdbbe2fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/1300/command-2127837197167660-3605329726:11: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_train[\"based_adults\"] = X_train[\"based_adults\"].astype(float)\n/root/.ipykernel/1300/command-2127837197167660-3605329726:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_train[\"based_childs\"] = X_train[\"based_childs\"].astype(float)\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages/mlflow/types/utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages/mlflow/types/schema.py:679: FutureWarning: `optional` is deprecated and will be removed in a future version of MLflow. Use `required` instead.\n  warnings.warn(\n2025/06/09 17:40:47 INFO mlflow.tracking._tracking_service.client: \uD83C\uDFC3 View run giridhar-hotres-model-fe at: https://dbc-c2e8445d-159d.cloud.databricks.com/ml/experiments/3264736349207955/runs/1ab48571924140a7a8f703f196d96cd8.\n2025/06/09 17:40:47 INFO mlflow.tracking._tracking_service.client: \uD83E\uDDEA View experiment at: https://dbc-c2e8445d-159d.cloud.databricks.com/ml/experiments/3264736349207955.\nRegistered model 'mlops_dev.giridhar.giridhar_hotres_model_fe_demo' already exists. Creating a new version of this model...\nCreated version '24' of model 'mlops_dev.giridhar.giridhar_hotres_model_fe_demo'.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/Shared/giridhar-hotres-model-fe\")\n",
    "with mlflow.start_run(run_name=\"giridhar-hotres-model-fe\",\n",
    "                      tags={\"git_sha\": \"1234567890abcdefgh\",\n",
    "                            \"branch\": \"week3\"},\n",
    "                            description=\"demo run for FE model logging\") as run:\n",
    "    # Log parameters and metrics\n",
    "    run_id = run.info.run_id\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM classifier with preprocessing\")\n",
    "    mlflow.log_params(train_parameters)\n",
    "\n",
    "    X_train[\"based_adults\"] = X_train[\"based_adults\"].astype(float)\n",
    "    X_train[\"based_childs\"] = X_train[\"based_childs\"].astype(float)\n",
    "\n",
    "\n",
    "    # Log the model\n",
    "    signature = infer_signature(model_input=X_train, model_output=pipeline.predict(X_train))\n",
    "    fe.log_model(\n",
    "                model=pipeline,\n",
    "                flavor=mlflow.sklearn,\n",
    "                artifact_path=\"lightgbm-pipeline-model-fe\",\n",
    "                training_set=training_set,\n",
    "                signature=signature,\n",
    "            )\n",
    "model_name = f\"{config.catalog_name}.{config.schema_name}.giridhar_hotres_model_fe_demo\"\n",
    "model_version = mlflow.register_model(\n",
    "    model_uri=f'runs:/{run_id}/lightgbm-pipeline-model-fe',\n",
    "    name=model_name,\n",
    "    tags={\"git_sha\": \"1234567890abcd\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0637c61-3d1d-4410-97a9-02d0392a28ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# features = [f for f in [\"Booking_ID\"] + num_features_adjusted + config.cat_features if f not in lookup_features]\n",
    "# features += ['room_type_reserved', 'market_segment_type', 'required_car_parking_space', 'type_of_meal_plan', 'month_as_cos', 'month_as_sin', 'based_adults', 'based_childs', 'update_timestamp_utc', 'no_of_adults', 'no_of_children']\n",
    "# print(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "161b1efd-530a-4626-9d8d-6a1795661fc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # 1) Print the schema to confirm both lookup cols are present\n",
    "# test_set_with_new_id.printSchema()\n",
    "\n",
    "# # 2) Peek at a few rows of those columns\n",
    "# test_set_with_new_id.select(\"Booking_ID\",\"based_adults\",\"based_childs\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee7c3467-662e-4412-bb64-6adce6d12969",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 17:40:52 WARNING mlflow.pyfunc: Calling `spark_udf()` with `env_manager=\"local\"` does not recreate the same environment that was used during training, which may lead to errors or inaccurate predictions. We recommend specifying `env_manager=\"conda\"`, which automatically recreates the environment that was used to train the model and performs inference in the recreated environment.\n2025/06/09 17:40:52 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n|Booking_ID|  prediction|\n+----------+------------+\n| aINN04969|Not_Canceled|\n| aINN34541|Not_Canceled|\n| aINN36109|Not_Canceled|\n| aINN01554|    Canceled|\n| aINN24975|Not_Canceled|\n+----------+------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat, lit\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# 1) Build the raw scoring DF (keep all columns, just prefix IDs)\n",
    "scoring_df = test_set.withColumn(\n",
    "    \"Booking_ID\",\n",
    "    concat(lit(\"a\"), col(\"Booking_ID\"))\n",
    ")\n",
    "\n",
    "# 2) Score with FE client against version 18\n",
    "preds2 = fe.score_batch(\n",
    "    model_uri=f\"models:/{model_name}/{model_version.version}\",\n",
    "    df=scoring_df,\n",
    "    result_type=StringType()\n",
    ")\n",
    "\n",
    "# 3) Inspect\n",
    "preds2.select(\"Booking_ID\", \"prediction\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d66bc41-d4e6-44ee-8c0e-19cace74b252",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# make predictions for a non-existing entry -> no error!\n",
    "# predictions.select(\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9fe6d98-db1f-43a2-a32a-3276f1bce9b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "region_name = \"eu-west-1\"\n",
    "aws_access_key_id = os.environ[\"aws_access_key_id\"]\n",
    "aws_secret_access_key = os.environ[\"aws_secret_access_key\"]\n",
    "\n",
    "client = boto3.client(\n",
    "    'dynamodb',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=region_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcb9e4b1-9a86-4131-8fe3-53c694ffd897",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table already exists; skipping creation.\n"
     ]
    }
   ],
   "source": [
    "# to check if the table exists already \n",
    "\n",
    "import botocore\n",
    "\n",
    "try:\n",
    "    client.describe_table(TableName='GiridharHotelReservationFeatures')\n",
    "    print(\"Table already exists; skipping creation.\")\n",
    "except client.exceptions.ResourceNotFoundException:\n",
    "    client.create_table(\n",
    "        TableName='GiridharHotelReservationFeatures',\n",
    "        KeySchema=[{'AttributeName': 'Booking_ID', 'KeyType': 'HASH'}],\n",
    "        AttributeDefinitions=[{'AttributeName': 'Booking_ID', 'AttributeType': 'S'}],\n",
    "        ProvisionedThroughput={'ReadCapacityUnits': 5, 'WriteCapacityUnits': 5}\n",
    "    )\n",
    "    print(\"Table created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3151c1a-5cf8-4bf0-b2ab-55a6059b17f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Commenting for now \n",
    "\n",
    "# response = client.create_table(\n",
    "#     TableName='GiridharHotelReservationFeatures',\n",
    "#     KeySchema=[\n",
    "#         {\n",
    "#             'AttributeName': 'Booking_ID',\n",
    "#             'KeyType': 'HASH'  # Partition key\n",
    "#         }\n",
    "#     ],\n",
    "#     AttributeDefinitions=[\n",
    "#         {\n",
    "#             'AttributeName': 'Booking_ID',\n",
    "#             'AttributeType': 'S'  # String\n",
    "#         }\n",
    "#     ],\n",
    "#     ProvisionedThroughput={\n",
    "#         'ReadCapacityUnits': 5,\n",
    "#         'WriteCapacityUnits': 5\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# print(\"Table creation initiated:\", response['TableDescription']['TableName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "158f451a-e169-4c41-8729-b862348a9f9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'MH5PCQ4INAVE8D0TE4KRKPNA13VV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'Server',\n",
       "   'date': 'Mon, 09 Jun 2025 17:41:01 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'MH5PCQ4INAVE8D0TE4KRKPNA13VV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "   'x-amz-crc32': '2745614147'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.put_item(\n",
    "    TableName='GiridharHotelReservationFeatures',\n",
    "    Item={\n",
    "        'Booking_ID': {'S': 'eINN33712'},\n",
    "        'no_of_adults': {'N': '4'},\n",
    "        'no_of_children': {'N': '10'},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b4ed45a-1999-436e-bdd4-1a4adb634500",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_of_adults': {'N': '4'}, 'no_of_children': {'N': '10'}, 'Booking_ID': {'S': 'eINN33712'}}\n"
     ]
    }
   ],
   "source": [
    "response = client.get_item(\n",
    "    TableName='GiridharHotelReservationFeatures',\n",
    "    Key={\n",
    "        'Booking_ID': {'S': 'eINN33712'}\n",
    "    }\n",
    ")\n",
    "\n",
    "# Extract the item from the response\n",
    "item = response.get('Item')\n",
    "print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebc07a97-62b8-4ca4-aaa0-3c57d32d4f08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: all 25 items written.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import boto3\n",
    "\n",
    "# (Assumes boto3 can already pick up credentials/region from your cluster)\n",
    "# client = boto3.client(\"dynamodb\")\n",
    "\n",
    "\n",
    "rows = spark.table(feature_table_name).toPandas().to_dict(orient=\"records\")\n",
    "\n",
    "def to_dynamodb_item(row):\n",
    "    return {\n",
    "        'PutRequest': {\n",
    "            'Item': {\n",
    "                'Booking_ID': {'S': str(row['Booking_ID'])},\n",
    "                'no_of_adults': {'N': str(row['no_of_adults'])},\n",
    "                'no_of_children': {'N': str(row['no_of_children'])}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "items = [to_dynamodb_item(row) for row in rows]\n",
    "\n",
    "# limiting the number of batches\n",
    "limit = 1 * 25\n",
    "sliced_items = items[:limit]\n",
    "\n",
    "\n",
    "def chunks(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i : i + n]\n",
    "\n",
    "for idx, batch in enumerate(chunks(sliced_items, 25), start=1):\n",
    "    to_send = batch\n",
    "    attempt = 1\n",
    "    while to_send:\n",
    "        response = client.batch_write_item(RequestItems={'GiridharHotelReservationFeatures': to_send})\n",
    "        unprocessed = response.get('UnprocessedItems', {}).get('GiridharHotelReservationFeatures', [])\n",
    "        if unprocessed:\n",
    "            print(f\"Batch {idx} attempt {attempt}: {len(unprocessed)} unprocessed, retrying...\")\n",
    "            to_send = unprocessed\n",
    "            attempt += 1\n",
    "            time.sleep(1)  # small backoff before retry\n",
    "        else:\n",
    "            print(f\"Batch {idx}: all {len(batch)} items written.\")\n",
    "            to_send = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6944b501-21f0-4b3f-8793-f2a6f10c3ce8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch payload:\n[{'PutRequest': {'Item': {'Booking_ID': {'S': 'INN25630'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '1'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN14474'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '1'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN23721'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN05844'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN18710'},\n                          'no_of_adults': {'N': '1'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN07412'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '1'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN22966'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN25678'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN33712'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN20728'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '2'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN06177'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN08935'},\n                          'no_of_adults': {'N': '1'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN06713'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN19753'},\n                          'no_of_adults': {'N': '1'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN21524'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN21650'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN07135'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN31510'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN02605'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN15870'},\n                          'no_of_adults': {'N': '3'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN11829'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN29923'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN08319'},\n                          'no_of_adults': {'N': '1'},\n                          'no_of_children': {'N': '0'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN04660'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '2'}}}},\n {'PutRequest': {'Item': {'Booking_ID': {'S': 'INN05569'},\n                          'no_of_adults': {'N': '2'},\n                          'no_of_children': {'N': '0'}}}}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# look at the first batch payload\n",
    "first_batch = list(chunks(sliced_items, 25))[0]\n",
    "print(\"First batch payload:\")\n",
    "pprint(first_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c37af2b7-5b04-4f6d-b8a3-e0a188ff46de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We ran into more limitations when we tried complex data types as output of a feature function\n",
    "# and then tried to use it for serving\n",
    "# al alternatve solution: using an external database (we use DynamoDB here)\n",
    "\n",
    "# create a DynamoDB table\n",
    "# insert records into dynamo DB & read from dynamoDB\n",
    "\n",
    "# create a pyfunc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea936ee7-13af-49d0-811a-bdb8e1148baa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# class HousePriceModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "#     \"\"\"Wrapper class for machine learning models to be used with MLflow.\n",
    "\n",
    "#     This class wraps a machine learning model for predicting house prices.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, model: object) -> None:\n",
    "#         \"\"\"Initialize the HousePriceModelWrapper.\n",
    "\n",
    "#         :param model: The underlying machine learning model.\n",
    "#         \"\"\"\n",
    "#         self.model = model\n",
    "    \n",
    "#     def predict(self, context, model_input):\n",
    "#         parsed = []\n",
    "#         for lookup_id in model_input[\"Booking_ID\"]:\n",
    "#             response = client.get_item(\n",
    "#                 TableName=\"GiridharHotelReservationFeatures\",\n",
    "#                 Key={\"Booking_ID\": {\"S\": lookup_id}}\n",
    "#             )\n",
    "#             raw_item = response.get(\"Item\")\n",
    "#             if not raw_item:\n",
    "#                 # No record found; decide what makes sense (e.g., skip or fill with defaults)\n",
    "#                 print(f\"Warning: Booking_ID {lookup_id} not found in DynamoDB.\")\n",
    "#                 continue\n",
    "            \n",
    "#             parsed_dict = {\n",
    "#                 key: int(value[\"N\"]) if \"N\" in value else value[\"S\"]\n",
    "#                 for key, value in raw_item.items()\n",
    "#             }\n",
    "#             parsed.append(parsed_dict)\n",
    "\n",
    "#         # Now `parsed` contains only the records that existed.\n",
    "#         # Continue with whatever your model expects:\n",
    "#         return super().predict(context=context, model_input=parsed)\n",
    "\n",
    "\n",
    "#     # def predict(\n",
    "#     #     self, context: mlflow.pyfunc.PythonModelContext, model_input: pd.DataFrame | np.ndarray\n",
    "#     # ) -> dict[str, float]:\n",
    "#     #     \"\"\"Make predictions using the wrapped model.\n",
    "\n",
    "#     #     :param context: The MLflow context (unused in this implementation).\n",
    "#     #     :param model_input: Input data for making predictions.\n",
    "#     #     :return: A dictionary containing the adjusted prediction.\n",
    "#     #     \"\"\"\n",
    "#     #     client = boto3.client('dynamodb',\n",
    "#     #                                aws_access_key_id=os.environ[\"aws_access_key_id\"],\n",
    "#     #                                aws_secret_access_key=os.environ[\"aws_secret_access_key\"],\n",
    "#     #                                region_name=os.environ[\"region_name\"])\n",
    "        \n",
    "#     #     parsed = []\n",
    "#     #     for lookup_id in model_input[\"Booking_ID\"]:\n",
    "#     #         raw_item = client.get_item(\n",
    "#     #             TableName='GiridharHotelReservationFeatures',\n",
    "#     #             Key={'Booking_ID': {'S': lookup_id}})[\"Item\"]     \n",
    "#     #         parsed_dict = {key: int(value['N']) if 'N' in value else value['S']\n",
    "#     #                   for key, value in raw_item.items()}\n",
    "#     #         parsed.append(parsed_dict)\n",
    "#     #     lookup_df=pd.DataFrame(parsed)\n",
    "#     #     merged_df = model_input.merge(lookup_df, on=\"Booking_ID\", how=\"left\").drop(\"Booking_ID\", axis=1)\n",
    "        \n",
    "#     #     merged_df[\"no_of_adults\"] = merged_df[\"no_of_adults\"].fillna(2)\n",
    "#     #     merged_df[\"no_of_children\"] = merged_df[\"no_of_children\"].fillna(2)\n",
    "#     #     merged_df[\"adults_and_childs\"] = merged_df[\"no_of_adults\"] + merged_df[\"no_of_children\"]\n",
    "#     #     predictions = self.model.predict(merged_df)\n",
    "\n",
    "#     #     return [int(x) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abdaa724-d37e-4617-9f8f-c5b05e6b24b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import mlflow.pyfunc\n",
    "from datetime import datetime\n",
    "\n",
    "class HousePriceModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, model: object) -> None:\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, context, model_input: pd.DataFrame) -> list[int]:\n",
    "        # create the DynamoDB client here\n",
    "        client = boto3.client(\n",
    "            'dynamodb',\n",
    "            aws_access_key_id=os.environ[\"aws_access_key_id\"],\n",
    "            aws_secret_access_key=os.environ[\"aws_secret_access_key\"],\n",
    "            region_name=os.environ.get(\"region_name\", \"eu-west-1\"),\n",
    "        )\n",
    "\n",
    "        parsed = []\n",
    "        for lookup_id in model_input[\"Booking_ID\"]:\n",
    "            resp = client.get_item(\n",
    "                TableName='GiridharHotelReservationFeatures',\n",
    "                Key={'Booking_ID': {'S': lookup_id}}\n",
    "            )\n",
    "            item = resp.get(\"Item\")\n",
    "            # if not item:\n",
    "            #     # default logic or skip\n",
    "            #     parsed.append({\"Booking_ID\": lookup_id,\n",
    "            #                    \"no_of_adults\": 1,       # default\n",
    "            #                    \"no_of_children\": 1})\n",
    "            # else:\n",
    "            #     parsed.append({\n",
    "            #         \"Booking_ID\": lookup_id,\n",
    "            #         \"no_of_adults\": int(item[\"no_of_adults\"][\"N\"]),\n",
    "            #         \"no_of_children\": int(item[\"no_of_children\"][\"N\"])\n",
    "            #     })\n",
    "            # Always produce `based_adults` and `based_childs`\n",
    "            if not item:\n",
    "                adults = 1\n",
    "                childs = 1\n",
    "            else:\n",
    "                adults = int(item[\"no_of_adults\"][\"N\"])\n",
    "                childs = int(item[\"no_of_children\"][\"N\"])\n",
    "                parsed.append({\n",
    "                    \"Booking_ID\": lookup_id,\n",
    "                    \"based_adults\": adults,\n",
    "                    \"based_childs\": childs\n",
    "                })\n",
    "\n",
    "        # merge and drop the ID column\n",
    "        # merged = model_input.merge(lookup_df, on=\"Booking_ID\", how=\"left\").drop(\"Booking_ID\", axis=1)\n",
    "        lookup_df = pd.DataFrame(parsed)\n",
    "        merged = (model_input.merge(lookup_df, on=\"Booking_ID\", how=\"left\")\n",
    "            # .drop(\"Booking_ID\", axis=1)\n",
    "        )\n",
    "        # Drop the ID and pass all features + based_* into the model\n",
    "        X = merged.drop(\"Booking_ID\", axis=1)\n",
    "        # now run your pipeline\n",
    "        # preds = self.model.predict(merged)\n",
    "        preds = self.model.predict(X)\n",
    "        return list(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0b272c2-957a-4812-aa16-b5268da90b79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "custom_model = HousePriceModelWrapper(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f269b7e-0e02-4e8d-8321-7853290feb54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 of 25 rows:\n+-----------------+--------------------------+------------------+-------------------+------------+--------------+--------------------+-----------------+---------+--------------+----------------------------+------------------------------------+------------------+----------------------+------------+------------+-------------+--------------+----------+-----------------------+-----------------------+-----------------------+\n|type_of_meal_plan|required_car_parking_space|room_type_reserved|market_segment_type|no_of_adults|no_of_children|no_of_weekend_nights|no_of_week_nights|lead_time|repeated_guest|no_of_previous_cancellations|no_of_previous_bookings_not_canceled|avg_price_per_room|no_of_special_requests|arrival_date|arrival_year|arrival_month|booking_status|Booking_ID|month_as_sin           |month_as_cos           |update_timestamp_utc   |\n+-----------------+--------------------------+------------------+-------------------+------------+--------------+--------------------+-----------------+---------+--------------+----------------------------+------------------------------------+------------------+----------------------+------------+------------+-------------+--------------+----------+-----------------------+-----------------------+-----------------------+\n|Meal Plan 1      |0                         |Room_Type 1       |Online             |2           |1             |2                   |1                |26       |0             |0                           |0                                   |161.0             |0                     |17          |2017        |10           |Not_Canceled  |INN25630  |-0.8660254037844386    |0.5000000000000001     |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 1       |Online             |2           |1             |1                   |1                |98       |0             |0                           |0                                   |121.5             |2                     |16          |2018        |7            |Not_Canceled  |INN14474  |-0.4999999999999997    |-0.8660254037844388    |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 1       |Offline            |2           |0             |0                   |3                |433      |0             |0                           |0                                   |70.0              |0                     |8           |2018        |9            |Canceled      |INN23721  |-1.0                   |-1.8369701987210297E-16|2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 1       |Offline            |2           |0             |2                   |5                |195      |0             |0                           |0                                   |72.25             |0                     |8           |2018        |8            |Not_Canceled  |INN05844  |-0.8660254037844385    |-0.5000000000000004    |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 1       |Offline            |1           |0             |0                   |2                |188      |0             |0                           |0                                   |130.0             |0                     |15          |2018        |6            |Canceled      |INN18710  |1.2246467991473532E-16 |-1.0                   |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 1       |Online             |2           |1             |0                   |3                |74       |0             |0                           |0                                   |112.5             |1                     |6           |2018        |4            |Canceled      |INN07412  |0.8660254037844387     |-0.4999999999999998    |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 1       |Offline            |2           |0             |1                   |2                |273      |0             |0                           |0                                   |95.0              |0                     |13          |2018        |5            |Canceled      |INN22966  |0.49999999999999994    |-0.8660254037844387    |2025-05-19 18:42:57.888|\n|Not Selected     |0                         |Room_Type 1       |Online             |2           |0             |1                   |3                |6        |0             |0                           |0                                   |66.3              |0                     |15          |2018        |12           |Not_Canceled  |INN25678  |-2.4492935982947064E-16|1.0                    |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 1       |Online             |2           |0             |2                   |5                |89       |0             |0                           |0                                   |83.66             |1                     |21          |2018        |3            |Not_Canceled  |INN33712  |1.0                    |6.123233995736766E-17  |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 6       |Online             |2           |2             |2                   |0                |56       |0             |0                           |0                                   |180.0             |1                     |20          |2018        |3            |Canceled      |INN20728  |1.0                    |6.123233995736766E-17  |2025-05-19 18:42:57.888|\n|Meal Plan 1      |1                         |Room_Type 1       |Online             |2           |0             |1                   |5                |103      |0             |0                           |0                                   |114.3             |1                     |12          |2018        |7            |Not_Canceled  |INN06177  |-0.4999999999999997    |-0.8660254037844388    |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 1       |Online             |1           |0             |4                   |11               |155      |0             |0                           |0                                   |117.42            |0                     |30          |2018        |8            |Canceled      |INN08935  |-0.8660254037844385    |-0.5000000000000004    |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 5       |Online             |2           |0             |0                   |1                |3        |0             |0                           |0                                   |128.8             |0                     |11          |2018        |6            |Not_Canceled  |INN06713  |1.2246467991473532E-16 |-1.0                   |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 1       |Offline            |1           |0             |1                   |2                |180      |0             |0                           |0                                   |120.0             |0                     |10          |2018        |10           |Canceled      |INN19753  |-0.8660254037844386    |0.5000000000000001     |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 1       |Online             |2           |0             |0                   |4                |92       |0             |0                           |0                                   |89.85             |2                     |12          |2018        |7            |Not_Canceled  |INN21524  |-0.4999999999999997    |-0.8660254037844388    |2025-05-19 18:42:57.888|\n|Meal Plan 2      |0                         |Room_Type 1       |Offline            |2           |0             |0                   |2                |56       |0             |0                           |0                                   |82.0              |0                     |17          |2017        |9            |Not_Canceled  |INN21650  |-1.0                   |-1.8369701987210297E-16|2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 1       |Online             |2           |0             |0                   |3                |279      |0             |0                           |0                                   |110.0             |0                     |12          |2018        |10           |Canceled      |INN07135  |-0.8660254037844386    |0.5000000000000001     |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 1       |Online             |2           |0             |0                   |2                |134      |0             |0                           |0                                   |114.3             |1                     |10          |2018        |8            |Not_Canceled  |INN31510  |-0.8660254037844385    |-0.5000000000000004    |2025-05-19 18:42:57.888|\n|Not Selected     |0                         |Room_Type 1       |Online             |2           |0             |0                   |2                |8        |0             |0                           |0                                   |139.0             |1                     |25          |2018        |3            |Not_Canceled  |INN02605  |1.0                    |6.123233995736766E-17  |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 4       |Online             |3           |0             |2                   |2                |10       |0             |0                           |0                                   |172.0             |2                     |29          |2018        |4            |Not_Canceled  |INN15870  |0.8660254037844387     |-0.4999999999999998    |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 1       |Online             |2           |0             |2                   |0                |2        |0             |0                           |0                                   |148.0             |1                     |21          |2018        |8            |Not_Canceled  |INN11829  |-0.8660254037844385    |-0.5000000000000004    |2025-05-19 18:42:57.888|\n|Not Selected     |0                         |Room_Type 1       |Online             |2           |0             |1                   |2                |52       |0             |0                           |0                                   |79.5              |1                     |26          |2018        |2            |Canceled      |INN29923  |0.8660254037844386     |0.5000000000000001     |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 1       |Offline            |1           |0             |2                   |1                |116      |0             |0                           |0                                   |61.0              |0                     |28          |2018        |2            |Canceled      |INN08319  |0.8660254037844386     |0.5000000000000001     |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 6       |Online             |2           |2             |0                   |2                |89       |0             |0                           |0                                   |186.3             |0                     |21          |2018        |7            |Canceled      |INN04660  |-0.4999999999999997    |-0.8660254037844388    |2025-05-19 18:42:57.888|\n|Meal Plan 1      |0                         |Room_Type 1       |Online             |2           |0             |1                   |2                |193      |0             |0                           |0                                   |120.0             |0                     |20          |2018        |6            |Canceled      |INN05569  |1.2246467991473532E-16 |-1.0                   |2025-05-19 18:42:57.888|\n+-----------------+--------------------------+------------------+-------------------+------------+--------------+--------------------+-----------------+---------+--------------+----------------------------+------------------------------------+------------------+----------------------+------------+------------+-------------+--------------+----------+-----------------------+-----------------------+-----------------------+\n\nMissing IDs: set()\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# 25 raw IDs out of first_batch\n",
    "ids25 = [rec[\"PutRequest\"][\"Item\"][\"Booking_ID\"][\"S\"] for rec in first_batch]\n",
    "\n",
    "\n",
    "raw_test_df = spark.table(feature_table_name)\n",
    "\n",
    "matched = train_set.filter(col(\"Booking_ID\").isin(ids25))\n",
    "\n",
    "print(f\"Found {matched.count()} of {len(ids25)} rows:\")\n",
    "matched.show(25, truncate=False)\n",
    "\n",
    "found_ids = [r.Booking_ID for r in matched.select(\"Booking_ID\").collect()]\n",
    "missing = set(ids25) - set(found_ids)\n",
    "print(\"Missing IDs:\", missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b7dd295-29bf-4377-ae39-eb14e79cc800",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns in df_input: {'based_childs', 'based_adults'}\nExtra   columns in df_input: {'booking_status', 'no_of_adults', 'update_timestamp_utc', 'no_of_children', 'month_as_cos', 'Booking_ID', 'month_as_sin'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_input = matched.toPandas().reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_cols = set(X_train.columns)\n",
    "input_cols = set(df_input.columns)\n",
    "missing = train_cols - input_cols\n",
    "extra   = input_cols - train_cols\n",
    "print(\"Missing columns in df_input:\", missing)\n",
    "print(\"Extra   columns in df_input:\", extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5c2cb00-a43b-4d93-8983-9238bd4b40cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_input = matched.toPandas().reset_index(drop=True)\n",
    "# print(\"Input cols:\", df_input.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75a4c186-c93f-4f8e-a160-7078b3f9cfef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Score\n",
    "custom_model = HousePriceModelWrapper(pipeline)\n",
    "preds25 = custom_model.predict(None, df_input)\n",
    "\n",
    "# df_input[\"prediction\"] = preds25\n",
    "# display(df_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f680dd7-a5d4-4114-9a7f-9a16a809d495",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages/mlflow/types/utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n2025/06/09 17:41:15 INFO mlflow.tracking._tracking_service.client: \uD83C\uDFC3 View run giridhar-demo-run-model-fe-pyfunc at: https://dbc-c2e8445d-159d.cloud.databricks.com/ml/experiments/3648643376455240/runs/8cf6087f84fb418a8d6d4172d1686d1f.\n2025/06/09 17:41:15 INFO mlflow.tracking._tracking_service.client: \uD83E\uDDEA View experiment at: https://dbc-c2e8445d-159d.cloud.databricks.com/ml/experiments/3648643376455240.\n"
     ]
    }
   ],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# df_input: a small Pandas DataFrame with the three columns your wrapper.predict expects\n",
    "# preds: the list of predictions from custom_model.predict(None, df_input)\n",
    "\n",
    "preds25 = custom_model.predict(None, df_input)\n",
    "\n",
    "# Now infer signature off df_input and its preds\n",
    "sig = infer_signature(df_input, pd.Series(preds25, name=\"prediction\"))\n",
    "\n",
    "mlflow.set_experiment(\"/Shared/giridhar-demo-model-fe-pyfunc\")\n",
    "with mlflow.start_run(run_name=\"giridhar-demo-run-model-fe-pyfunc\") as run:\n",
    "    mlflow.pyfunc.log_model(\n",
    "        python_model=custom_model,\n",
    "        artifact_path=\"lightgbm-pipeline-model-fe\",\n",
    "        signature=sig\n",
    "    )\n",
    "    run_id = run.info.run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91b1e3dc-acbf-45b4-8f81-7f517689f820",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# set the the train parameters \n",
    "\n",
    "train_parameters = {\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"n_estimators\": 1000,\n",
    "            \"max_depth\": 8,\n",
    "            \"num_leaves\": 31,\n",
    "            \"min_child_samples\": 20,\n",
    "            \"subsample\": 0.8,\n",
    "            \"colsample_bytree\": 0.8,\n",
    "            \"random_state\": 42,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a854a4e-098c-4ab6-9e92-f0b747054a8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #log model\n",
    "# mlflow.set_experiment(\"/Shared/giridhar-hotres-model-fe-pyfunc\")\n",
    "# with mlflow.start_run(run_name=\"giridhar-hoteres-model-fe-pyfunc\",\n",
    "#                       tags={\"git_sha\": \"1234567890abcd\",\n",
    "#                             \"branch\": \"week2\"},\n",
    "#                             description=\"demo run for FE model logging\") as run:\n",
    "#     # Log parameters and metrics\n",
    "#     run_id = run.info.run_id\n",
    "#     mlflow.log_param(\"model_type\", \"LightGBM with preprocessing\")\n",
    "#     mlflow.log_params(train_parameters)\n",
    "\n",
    "#     # Log the model\n",
    "#     signature = infer_signature(model_input=data, model_output=custom_model.predict(context=None, model_input=data))\n",
    "#     mlflow.pyfunc.log_model(\n",
    "#                 python_model=custom_model,\n",
    "#                 artifact_path=\"lightgbm-pipeline-model-fe\",\n",
    "#                 signature=signature,\n",
    "#             )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfb82cd5-ce9f-4732-ac06-327cb686ceba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 17:41:29 INFO mlflow.models.python_api: Your input data has been transformed to comply with the expected input format for the MLflow scoring server. If you want to deploy the model to online serving, make sure to apply the same preprocessing in your inference client. Please also refer to https://www.mlflow.org/docs/latest/deployment/deploy-model-locally.html#json-input for more details on the supported input format.\n\nOriginal input data:\n  type_of_meal_plan  ...    update_timestamp_utc\n0       Meal Plan 1  ... 2025-05-19 18:42:57.888\n\n[1 rows x 22 columns]\n\nTransformed input data:\n{\"dataframe_split\": {\"index\": [0], \"columns\": [\"type_of_meal_plan\", \"required_car_parking_space\", \"room_type_reserved\", \"market_segment_type\", \"no_of_adults\", \"no_of_children\", \"no_of_weekend_nights\", \"no_of_week_nights\", \"lead_time\", \"repeated_guest\", \"no_of_previous_cancellations\", \"no_of_previous_bookings_not_canceled\", \"avg_price_per_room\", \"no_of_special_requests\", \"arrival_date\", \"arrival_year\", \"arrival_month\", \"booking_status\", \"Booking_ID\", \"month_as_sin\", \"month_as_cos\", \"update_timestamp_utc\"], \"data\": [[\"Meal Plan 1\", 0, \"Room_Type 1\", \"Online\", 2, 1, 2, 1, 26, 0, 0, 0, 161.0, 0, 17, 2017, 10, \"Not_Canceled\", \"INN25630\", -0.8660254037844386, 0.5000000000000001, \"2025-05-19T18:42:57.888000\"]]}}\n2025/06/09 17:41:30 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n2025/06/09 17:41:31 INFO mlflow.utils.virtualenv: Installing python 3.11.11 if it does not exist\nDownloading Python-3.11.11.tar.xz...\n-> https://www.python.org/ftp/python/3.11.11/Python-3.11.11.tar.xz\nInstalling Python-3.11.11...\nInstalled Python-3.11.11 to /databricks/.pyenv/versions/3.11.11\n2025/06/09 17:43:46 INFO mlflow.utils.virtualenv: Creating a new environment in /root/.mlflow/envs/mlflow-1a9947897d590dfc2e1c6471b401a21cb035bd17 with /databricks/.pyenv/versions/3.11.11/bin/python\n2025/06/09 17:43:47 INFO mlflow.utils.virtualenv: Installing dependencies\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created virtual environment CPython3.11.11.final.0-64 in 358ms\n  creator CPython3Posix(dest=/root/.mlflow/envs/mlflow-1a9947897d590dfc2e1c6471b401a21cb035bd17, clear=False, no_vcs_ignore=False, global=False)\n  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n    added seed packages: pip==23.2.1, setuptools==68.0.0, wheel==0.41.0\n  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n2025/06/09 17:44:40 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /root/.mlflow/envs/mlflow-1a9947897d590dfc2e1c6471b401a21cb035bd17/bin/activate && python -c \"\"']'\n2025/06/09 17:44:40 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /root/.mlflow/envs/mlflow-1a9947897d590dfc2e1c6471b401a21cb035bd17/bin/activate && python /local_disk0/.ephemeral_nfs/envs/pythonEnv-9dad1bc5-209a-49be-b7b7-e91b639a028b/lib/python3.11/site-packages/mlflow/pyfunc/_mlflow_pyfunc_backend_predict.py --model-uri file:///local_disk0/repl_tmp_data/ReplId-19755-c2c9b-7/tmp30zc0gwd/lightgbm-pipeline-model-fe --content-type json --input-path /local_disk0/repl_tmp_data/ReplId-19755-c2c9b-7/tmp3umi_pt0/input.json']'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [\"Not_Canceled\"]}"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "mlflow.models.predict(f\"runs:/{run_id}/lightgbm-pipeline-model-fe\", df_input[0:1])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "week3. feature_engineering_demo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}